<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[seqkit 使用说明]]></title>
    <url>%2F2018%2F09%2F13%2Fseqkit-usage%2F</url>
    <content type="text"><![CDATA[seqkit 是 Wei Shen 使用 go 语言编写处理 fa 和 fq 文件的一把利器，当前介绍版本为0.8.0。这里不详细介绍各个函数的参数，官方给出的文档已经足够。 软件地址：https://github.com/shenwei356/seqkit 12345678910111213141516171819202122232425262728Available Commands: common find common sequences of multiple files by id/name/sequence concat concatenate sequences with same ID from multiple files convert convert FASTQ quality encoding between Sanger, Solexa and Illumina duplicate duplicate sequences N times faidx create FASTA index file and extract subsequence fq2fa convert FASTQ to FASTA fx2tab convert FASTA/Q to tabular format (with length/GC content/GC skew) genautocomplete generate shell autocompletion script grep search sequences by pattern(s) of name or sequence motifs head print first N FASTA/Q records help Help about any command locate locate subsequences/motifs range print FASTA/Q records in a range (start:end) rename rename duplicated IDs replace replace name/sequence by regular expression restart reset start position for circular genome rmdup remove duplicated sequences by id/name/sequence sample sample sequences by number or proportion seq transform sequences (revserse, complement, extract ID...) shuffle shuffle sequences sliding sliding sequences, circular genome supported sort sort sequences by id/name/sequence/length split split sequences into files by id/seq region/size/parts stats simple statistics of FASTA/Q files subseq get subsequences by region/gtf/bed, including flanking sequences tab2fx convert tabular format to FASTA/Q format version print version information and check for update seq12345678910$ seqkit seq hairpin.fa.gz #展示fa文件&gt;cel-let-7 MI0000001 Caenorhabditis elegans let-7 stem-loopUACACUGUGGAUCCGGUGAGGUAGUAGGUUGUAUAGUUUGGAAUAUUACCACCGGUGAACUAUGCAAUUUUCUACCUUACCGGAGACAGAACUCUUCGA$ seqkit seq read_1.fq.gz #展示fq文件@HWI-D00523:240:HF3WGBCXX:1:1101:2574:2226 1:N:0:CTGTAGTGAGGAATATTGGTCAATGGGCGCGAGCCTGAACCAGCCAAGTAGCGTGAAGGATGACTGCCCTACGGG+HIHIIIIIHIIHGHHIHHIIIIIIIIIIIIIIIHHIIIIIHHIHIIIIIGIHIIIIHHHHHHGHIHIII 12345678910111213141516171819202122$ seqkit seq hairpin.fa.gz -n #展示序列全名cel-let-7 MI0000001 Caenorhabditis elegans let-7 stem-loopcel-lin-4 MI0000002 Caenorhabditis elegans lin-4 stem-loopcel-mir-1 MI0000003 Caenorhabditis elegans miR-1 stem-loop$ seqkit seq hairpin.fa.gz -n -i #展示序列IDcel-let-7cel-lin-4cel-mir-1$ seqkit seq hairpin.fa.gz -n -i --id-regexp "^[^\s]+\s([^\s]+)\s" #使用正则匹配序列名MI0000001MI0000002MI0000003$ seqkit seq hairpin.fa.gz -s -w 0 #只展示序列 并设置每行碱基数为默认UACACUGUGGAUCCGGUGAGGUAGUAGGUUGUAUAGUUUGGAAUAUUACCACCGGUGAACUAUGCAAUUUUCUACCUUACCGGAGACAGAACUCUUCGAAUGCUUCCGGCCUGUUCCCUGAGACCUCAAGUGUGAGUGUACUAUUGAUGCUUCACACCUGGGCUCUCCGGGUACCAGGACGGUUUGAGCAGAUAAAGUGACCGUACCGAGCUGCAUACUUCCUUACAUGCCCAUACUAUAUCAUAAAUGGAUAUGGAAUGUAAAGAAGUAUGUAGAACGGGGUGGUAGU 123456789101112$ seqkit seq hairpin.fa.gz -r -p #反转录序列&gt;cel-let-7 MI0000001 Caenorhabditis elegans let-7 stem-loopUCGAAGAGUUCUGUCUCCGGUAAGGUAGAAAAUUGCAUAGUUCACCGGUGGUAAUAUUCCAAACUAUACAACCUACUACCUCACCGGAUCCACAGUGUA$ echo -e "&gt;seq\nACGT-actgc-ACC" | seqkit seq -g -u #去除序列gap 并大写碱基&gt;seqACGTACTGCACC$ echo -e "&gt;seq\nUCAUAUGCUUGUCUCAAAGAUUA" | seqkit seq --rna2dna #DNA转RNA,--dna2rna亦可&gt;seqTCATATGCTTGTCTCAAAGATTA subseq1234567891011121314151617181920212223242526272829$ zcat hairpin.fa.gz | seqkit subseq -r 1:12 #展示序列前12个碱基$ zcat hairpin.fa.gz | seqkit subseq -r -12:-1 #后12个$ cat t.fa&gt;seqactgACTGactgn$ cat t.gtf #注意gtf文件格式，必须以\t分割。seq test CDS 5 8 . . . gene_id "A"; transcript_id "";seq test CDS 5 8 . - . gene_id "B"; transcript_id "";$ seqkit subseq --gtf t.gtf t.fa #使用gtf位置信息，挑选fa序列&gt;seq_5:8:. AACTG&gt;seq_5:8:- BCAGT$ seqkit subseq --gtf Homo_sapiens.GRCh38.84.gtf.gz --chr 1 --feature cds hsa.fa &gt; chr1.gtf.cds.fa #指定染色体和特征$ seqkit subseq --gtf t.gtf t.fa -u 3 #另加3bp上游序列&gt;seq_5:8:._us:3 ActgACTG&gt;seq_5:8:-_us:3 BagtCAGT$ seqkit subseq --gtf t.gtf t.fa -u 3 -f #只取上游3bp序列&gt;seq_5:8:._usf:3 Actg&gt;seq_5:8:-_usf:3 Bagt gff3 文件第九列格式为ID=XXXXX; gtf 文件第九列格式为 gene_id “A”; transcript_id “”; stats123456$ seqkit stats *.f&#123;a,q&#125;.gz #统计序列信息file format type num_seqs sum_len min_len avg_len max_lenhairpin.fa.gz FASTA RNA 28,645 2,949,871 39 103 2,354mature.fa.gz FASTA RNA 35,828 781,222 15 21.8 34reads_1.fq.gz FASTQ DNA 2,500 567,516 226 227 229reads_2.fq.gz FASTQ DNA 2,500 560,002 223 224 225 faidx1234567$ seqkit faidx hairpin.fa #建立序列索引&gt;hsa-let-7a-1UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA&gt;hsa-let-7a-2AGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGAUAACUGUACAGCCUCCUAGCUUUCCU fq2fa1$ seqkit fq2fa reads_1.fq.gz -o reads1_.fa.gz #fq转fa convert123456789101112131415161718192021$ seqkit head -n 1 tests/Illimina1.8.fq.gz...#AAAFAAJFFFJJJ&lt;JJJJJFFFJFJJJJJFJJAJJJFJJFJFJJJJFAFJ&lt;JA&lt;FFJ7FJJFJJAAJJJJ&lt;JJJJJJJFJJJAJJJJJFJJ77&lt;JJJJ-F7A-FJFFJJJJJJ&lt;FFJ-&lt;7FJJJFJJ)A7)7AA&lt;7--)&lt;-7F-A7FA&lt;$ seqkit convert tests/Illimina1.8.fq.gz | seqkit head -n 1 #默认转换fq文件质量值到1.8+[INFO] possible quality encodings: [Illumina-1.8+][INFO] guessed quality encoding: Illumina-1.8+[INFO] converting Illumina-1.8+ -&gt; Sanger[WARN] source and target quality encoding match....#AAAFAAJFFFJJJ&lt;JJJJJFFFJFJJJJJFJJAJJJFJJFJFJJJJFAFJ&lt;JA&lt;FFJ7FJJFJJAAJJJJ&lt;JJJJJJJFJJJAJJJJJFJJ77&lt;JJJJ-F7A-FJFFJJJJJJ&lt;FFJ-&lt;7FJJJFJJ)A7)7AA&lt;7--)&lt;-7F-A7FA&lt;$ seqkit convert tests/Illimina1.8.fq.gz --to Illumina-1.5+ | seqkit head -n 1[INFO] possible quality encodings: [Illumina-1.8+] [INFO] guessed quality encoding: Illumina-1.8+[INFO] converting Illumina-1.8+ -&gt; Illumina-1.5+ #转换 Illumina1.8+ -&gt; Illumina1.5+...B```e``ieeeiii[iiiiieeeieiiiiieii`iiieiieieiiiie`ei[i`[eeiVeiieii``iiii[iiiiiiieiii`iiiiieiiVV[iiiiLeV`Leieeiiiiii[eeiL[VeiiieiiH`VHV``[VLLH[LVeL`Ve`[ grep123456789101112131415$ zcat hairpin.fa.gz | seqkit grep -r -p ^hsa #正则匹配序列名&gt;hsa-let-7a-1 MI0000060 Homo sapiens let-7a-1 stem-loopUGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA&gt;hsa-let-7a-2 MI0000061 Homo sapiens let-7a-2 stem-loopAGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGAUAACUGUACAGCCUCCUAGCUUUCCU$ zcat hairpin.fa.gz | seqkit grep -r -p ^hsa -p ^mmu -v #2个条件并取反$ zcat hairpin.fa.gz | seqkit grep -f list &gt; new.fa #将需要提取的序列名放在list中$ zcat hairpin.fa.gz | seqkit grep -s -r -i -p ^aggcg #正则匹配序列碱基，-i 忽略大小写$ seqkit grep -s -R 1:30 -i -r -p GCTGG #-R 在前30个碱基中正则匹配 rmdup12345678910$ zcat hairpin.fa.gz | seqkit rmdup -s -o clean.fa.gz #去除重复的序列[INFO] 2226 duplicated records removed$ zcat hairpin.fa.gz | seqkit rmdup -s -i -m -o clean.fa.gz -d duplicated.fa.gz -D duplicated.detail.txt #-d输出重复序列，-D统计重复序列$ cat duplicated.detail.txt # here is not the entire list3 hsa-mir-424, mml-mir-424, ppy-mir-4243 hsa-mir-342, mml-mir-342, ppy-mir-3422 ngi-mir-932, nlo-mir-9322 ssc-mir-9784-1, ssc-mir-9784-2 common123$ seqkit common file*.fa -o common.fasta #通过ID寻找共同序列$ seqkit common file*.fa -n -o common.fasta #通过全名$ seqkit common file*.fa -s -i -o common.fasta #通过序列 split1234567891011121314151617181920212223242526272829303132333435363738394041424344$ seqkit split hairpin.fa.gz -s 10000 #按序列数分割文件[INFO] split into 10000 seqs per file[INFO] write 10000 sequences to file: hairpin.fa.part_001.gz[INFO] write 10000 sequences to file: hairpin.fa.part_002.gz[INFO] write 8645 sequences to file: hairpin.fa.part_003.gz $ seqkit split hairpin.fa.gz -p 4 #按文件个数分割文件[INFO] split into 4 parts[INFO] read sequences ...[INFO] read 28645 sequences[INFO] write 7162 sequences to file: hairpin.fa.part_001.gz[INFO] write 7162 sequences to file: hairpin.fa.part_002.gz[INFO] write 7162 sequences to file: hairpin.fa.part_003.gz[INFO] write 7159 sequences to file: hairpin.fa.part_004.gz$ seqkit split hairpin.fa.gz -p 4 -2 #-2减少内存使用[INFO] split into 4 parts[INFO] read and write sequences to tempory file: hairpin.fa.gz.fa ...[INFO] create and read FASTA index ...[INFO] read sequence IDs from FASTA index ...[INFO] 28645 sequences loaded[INFO] write 7162 sequences to file: hairpin.part_001.fa.gz[INFO] write 7162 sequences to file: hairpin.part_002.fa.gz[INFO] write 7162 sequences to file: hairpin.part_003.fa.gz[INFO] write 7159 sequences to file: hairpin.part_004.fa.gz$ seqkit split hairpin.fa.gz -i --id-regexp "^([\w]+)\-" -2 #按ID[INFO] split by ID. idRegexp: ^([\w]+)\-[INFO] read and write sequences to tempory file: hairpin.fa.gz.fa ...[INFO] create and read FASTA index ...[INFO] create FASTA index for hairpin.fa.gz.fa[INFO] read sequence IDs from FASTA index ...[INFO] 28645 sequences loaded[INFO] write 48 sequences to file: hairpin.id_cca.fa.gz[INFO] write 3 sequences to file: hairpin.id_hci.fa.gz$ seqkit split hairpin.fa.gz -r 1:3 -2 #按前3个碱基[INFO] split by region: 1:3[INFO] read and write sequences to tempory file: hairpin.fa.gz.fa ...[INFO] read sequence IDs and sequence region from FASTA file ...[INFO] create and read FASTA index ...[INFO] write 463 sequences to file: hairpin.region_1:3_AUG.fa.gz[INFO] write 349 sequences to file: hairpin.region_1:3_ACU.fa.gz[INFO] write 311 sequences to file: hairpin.region_1:3_CGG.fa.gz range1$ cat hairpin.fa | seqkit range -r 101:150 #输出范围内的序列（1:12 如同 head -n 12） sort1234567891011121314151617181920$ echo -e "&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA" | seqkit sort --quiet #按ID排序，--quiet不输出提示信息&gt;SEQ2acgtnAAAA&gt;seq1ACGTNcccc$ echo -e "&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA" | seqkit sort --quiet -i #不区分大小写&gt;seq1ACGTNcccc&gt;SEQ2acgtnAAAA$ echo -e "&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAAnnn\n&gt;seq3\nacgt" | seqkit sort --quiet -l #按序列长度&gt;seq3acgt&gt;seq1ACGTNcccc&gt;SEQ2acgtnAAAAnnn 0.9.0版本中加入 -r 参数，可以反转排序结果。]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python标准库学习（一）]]></title>
    <url>%2F2018%2F09%2F11%2Fpython-standard-library-1%2F</url>
    <content type="text"><![CDATA[collections该模块实现专门的容器数据类型，提供Python通用内置容器（dict，set，list，tuple）的替代方案。 nametuple() 工厂函数用于创建带有命名字段的元组子类 deque() 列表式容器，在两端有快速附加和弹出 ChainMap() 类似于类的类，用于创建多个映射的单个视图 Counter () dict子类用于计算hashable对象 OrderedDict () dict子类，记住已添加的条目的顺序 defaultdict () dict子类调用一个工厂函数时提供缺失值 UserDict () 包装字典对象，更容易dict子类化 UserList () 包装列表对象以方便列表子类化 UserString() 包装字符串对象，更容易字符串子类化 ChainMapChainMap用来将多个dict(字典)组成一个list(只是比喻)，可以理解成合并多个字典，但和update不同，而且效率更高。 ChainMap用来将多个dict组成一个list之后，多个dict之间的键不冲突。当多个dict有重复键时，使用get方法：如chainMap.get(&#39;name&#39;)将会返回第一个dict[‘name’]。 123456789101112131415161718192021222324252627282930313233343536# 新建ChainMap及它的结构In[2]: from collections import ChainMapIn[3]: m1 = &#123;'color': 'red', 'user': 'guest'&#125;In[4]: m2 = &#123;'name': 'drfish', 'age': '18'&#125;In[5]: chainMap = ChainMap(m1, m2)In[6]: print(chainMap.items())ItemsView(ChainMap(&#123;'color': 'red', 'user': 'guest'&#125;, &#123;'name': 'drfish', 'age': '18'&#125;))# 获取ChainMap中的元素In[7]: print(chainMap.get('name'))drfishIn[8]: print(chainMap.get('not'))None# 新增mapIn[9]: m3 = &#123;'name': 'boy'&#125;In[10]: chainMap = chainMap.new_child(m3)In[11]: print(chainMap.items())ItemsView(ChainMap(&#123;'name': 'boy'&#125;, &#123;'color': 'red', 'user': 'guest'&#125;, &#123;'name': 'drfish', 'age': '18'&#125;))In[12]: print(chainMap.get('name'))'boy'#一次遍历多个字典In[13]: for i in chainMap.maps: print("----------------") for mykey in i.keys(): print(mykey,i[mykey]) ----------------name boy----------------color reduser guest----------------name drfishage 18 CounterCounter是一个简单的计数器，使用起来非常方便。 123456789101112131415161718192021&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; c = Counter(a=4, b=2, c=0, d=-2) #不大于0的全部忽略&gt;&gt;&gt; sorted(c.elements())['a', 'a', 'a', 'a', 'b', 'b']&gt;&gt;&gt; Counter('abracadabra').most_common(3) #返回出现次数最多的字符[('a', 5), ('r', 2), ('b', 2)]&gt;&gt;&gt; cnt = Counter() # 统计列表中元素出现的个数&gt;&gt;&gt; for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:... cnt[word] += 1...&gt;&gt;&gt; cntCounter(&#123;'blue': 3, 'red': 2, 'green': 1&#125;) &gt;&gt;&gt; cnt = Counter() # 统计字符串中元素出现的个数&gt;&gt;&gt; for ch in 'hello':... cnt[ch] = cnt[ch] + 1...&gt;&gt;&gt; cntCounter(&#123;'l': 2, 'o': 1, 'h': 1, 'e': 1&#125;) dequedeque就是一个双端队列，与list非常相似，不过可以同时在list的左边增删元素，支持线程安全 ，从队列两端添加或弹出元素的复杂度都是O(1)，而从列表的头部插入或移除元素时，列表的复杂度为O(N)。 deque和list从中部处理数据复杂度都为为O(N)。 123456789101112In[72]: dq = deque('abc')In[73]: dqOut[73]: deque(['a', 'b', 'c'])In[74]: dq.append('A')In[75]: dq.appendleft('Z')In[76]: dqOut[76]: deque(['Z', 'a', 'b', 'd', 'A'])In[77]: dq.popleft()Out[77]: 'Z'In[78]: dq.extendleft("hello")In[79]: dqOut[79]: deque(['o', 'l', 'l', 'e', 'h', 'a', 'b', 'c', 'A']) defaultdict使用 list 作为 default_factory，很容易将键值对的序列分组到列表的字典,类似setdefault 当第一次遇到每个键时，它不在映射中；因此使用返回空 list 的 default_factory 函数自动创建一个条目。然后，list.append() 操作将值附加到新列表。当再次遇到键时，查找继续正常（返回该键的列表），list.append() 操作将另一个值添加到列表。这种技术比使用 dict.setdefault() 的等效技术更简单和更快 12345678&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]&gt;&gt;&gt; d = defaultdict(list)&gt;&gt;&gt; for k, v in s:... d[k].append(v)...&gt;&gt;&gt; sorted(d.items())[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])] 1234567&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]&gt;&gt;&gt; for k, v in s:... d.setdefault(k,[]).append(v)...&gt;&gt;&gt; sorted(d.items())[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])] 将 default_factory 设置为int 使 defaultdict 可用于计数,当首次遇到字母时，映射中缺少字母，因此 default_factory 函数调用 int() 以提供默认计数为零。增量操作然后建立每个字母的计数。 1234567&gt;&gt;&gt; s = 'mississippi'&gt;&gt;&gt; d = defaultdict(int)&gt;&gt;&gt; for k in s:... d[k] += 1...&gt;&gt;&gt; sorted(d.items())[('i', 4), ('m', 1), ('p', 2), ('s', 4)] 将 default_factory 设置为 set使得 defaultdict 可用于构建集合的字典 1234567&gt;&gt;&gt; s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)]&gt;&gt;&gt; d = defaultdict(set)&gt;&gt;&gt; for k, v in s:... d[k].add(v)...&gt;&gt;&gt; sorted(d.items())[('blue', &#123;2, 4&#125;), ('red', &#123;1, 3&#125;)] OrderedDict有序字典与常规字典类似，但它们记住项目插入的顺序。在对有序字典进行迭代时，项目按它们的键首次添加的顺序返回。]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python-underscore]]></title>
    <url>%2F2018%2F09%2F10%2Fpython-underscore%2F</url>
    <content type="text"><![CDATA[_name以单下划线开头，表示这是一个保护成员，只有类对象和子类对象自己能访问到这些变量。以单下划线开头的变量和函数被默认当作是内部函数，使用from module improt *时不会被获取，但是使用import module可以获取 name_以单下划线结尾仅仅是为了区别该名称与关键词 __name双下划线开头，表示为私有成员，只允许类本身访问，子类也不行。在文本上被替换为_class__method name双下划线开头，双下划线结尾。一种约定，Python内部的名字，用来区别其他用户自定义的命名,以防冲突。是一些 Python 的“魔术”对象，表示这是一个特殊成员，例如：定义类的时候，若是添加init方法，那么在创建类的实例的时候，实例会自动调用这个方法，一般用来对实例的属性进行初使化，Python不建议将自己命名的方法写为这种形式]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ruby部分代码风格]]></title>
    <url>%2F2018%2F09%2F10%2Fruby-guide-tips%2F</url>
    <content type="text"><![CDATA[每个缩排层级使用两个空格。不要使用制表符. 123456789# 差 - 四个空格def some_method do_somethingend# 好def some_method do_somethingend 范围的字面量语法中，不要添加任何空格。 1234567# 差1 .. 3'a' ... 'z'# 好1..3'a'...'z' 使用 _ 语法改善大数的数值字面量的可读性。 12345# 差 - 有几个零？num = 1000000# 好 - 方便人脑理解num = 1_000_000 使用 def 定义方法时，如果有参数则使用括号，如果无参数则省略括号。 12345678910111213141516171819# 差def some_method() # 省略主体end# 好def some_method # 省略主体end# 差def some_method_with_parameters param1, param2 # 省略主体end# 好def some_method_with_parameters(param1, param2) # 省略主体end 除非必要，否则避免在并行赋值时使用单字符的 _ 变量。优先考虑前缀形式的下划线变量，而不是直接使用 _，因为前者可以提供一定的语义信息。但当赋值语句左侧出现带 * 操作符的变量时，使用 _ 也是可以接受的。 123456789101112131415foo = 'one,two,three,four,five'# 差 _可有可无，且无任何有用信息first, second, _ = foo.split(',')first, _, _ = foo.split(',')first, *_ = foo.split(',')# 好 _可有可无，但提供了额外信息first, _second = foo.split(',')first, _second, = foo.split(',')first, *_ending = foo.split(',')# 好 _占位符，_ 担当最后一个元素*beginning, _ = foo.split(',')*beginning, something, _ = foo.split(',') 永远不要使用 for， 除非你很清楚为什么。大部分情况下，你应该使用迭代器。for 是由 each 实现的，所以你绕弯了。另外，for 没有引入一个新的作用域 (each 有），因此在它内部定义的变量在外部仍是可见的。 123456789101112131415arr = [1, 2, 3]# 差for elem in arr do puts elemend# 注意，elem 可在 for 循环外部被访问elem # =&gt; 3# 好arr.each &#123; |elem| puts elem &#125;# 注意，elem 不可在 each 块外部被访问elem # =&gt; NameError: undefined local variable or method `elem' 倾向使用三元操作符（?:）而不是 if/then/else/end 结构。前者更为常见且简练。 12345# 差result = if some_condition then something else something_else end# 好result = some_condition ? something : something_else 永远不要使用 if x; ...。使用三元操作符来替代。 12345# 差result = if some_condition; something else something_else end# 好result = some_condition ? something : something_else 使用 ! 而不是 not。 12345# 差 - 因为操作符的优先级，这里必须使用括号x = (not something)# 好x = !something 永远不要使用 and 与 or 关键字。使用 &amp;&amp; 与 || 来替代。 12345678910111213141516# 差# 布尔表达式ok = got_needed_arguments and arguments_are_valid# 流程控制document.save or fail(RuntimeError, "Failed to save document!")# 好# 布尔表达式ok = got_needed_arguments &amp;&amp; arguments_are_valid# 流程控制fail(RuntimeError, "Failed to save document!") unless document.save# 流程控制document.save || fail(RuntimeError, "Failed to save document!") 对于单行主体，倾向使用 {...} 而不是 do...end。对于多行主体，避免使用 {...}。对于“流程控制”或“方法定义”（比如 Rakefile、其他 DSL 构成片段），总是使用 do...end。避免在链式方法调用中使用 do...end. 1234567891011121314151617names = %w[Bozhidar Steve Sarah]# 差names.each do |name| puts nameend# 好names.each &#123; |name| puts name &#125;# 差names.select do |name| name.start_with?('S')end.map &#123; |name| name.upcase &#125;# 好names.select &#123; |name| name.start_with?('S') &#125;.map(&amp;:upcase) 某些人可能会争论在多行链式方法调用时使用 {...} 看起来还可以。但他们应该扪心自问——这样的代码真的可读吗？难道不能把区块内容提取出来放到小巧的方法里吗？ #我觉得写成代码块易读。 避免在不需要流程控制的情况下使用 return。 123456789# 差def some_method(some_arr) return some_arr.sizeend# 好def some_method(some_arr) some_arr.sizeend 嗯。。。很魔幻。 通过使用范围或 Comparable#between? 来替代复杂的比较逻辑。 12345678# 差do_something if x &gt;= 1000 &amp;&amp; x &lt;= 2000# 好do_something if (1000..2000).include?(x)# 好do_something if x.between?(1000, 2000) 当创建一组元素为单词（没有空格或特殊字符）的数组时，倾向使用 %w 而不是 []。此规则只适用于数组元素有两个或以上的时候。 12345# 差STATES = ['draft', 'open', 'closed']# 好STATES = %w[draft open closed] 倾向使用符号而不是字符串作为哈希键。 12345# 差hash = &#123; 'one' =&gt; 1, 'two' =&gt; 2, 'three' =&gt; 3 &#125;# 好hash = &#123; 'one': 1, 'two': 2, 'three': 3 &#125; 倾向使用 Hash#each_key 而不是 Hash#keys.each，使用 Hash#each_value 而不是 Hash#values.each。 123456789# 差hash.keys.each &#123; |k| p k &#125;hash.values.each &#123; |v| p v &#125;hash.each &#123; |k, _v| p k &#125;hash.each &#123; |_k, v| p v &#125;# 好hash.each_key &#123; |k| p k &#125;hash.each_value &#123; |v| p v &#125;]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pandas学习（二）]]></title>
    <url>%2F2018%2F09%2F06%2Fpandas-2%2F</url>
    <content type="text"><![CDATA[算术运算和数据对齐pandas最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。看一个简单的例子： 123456789101112131415161718192021In [150]: s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])In [151]: s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], .....: index=['a', 'c', 'e', 'f', 'g'])In [152]: s1Out[152]: a 7.3c -2.5d 3.4e 1.5dtype: float64In [153]: s2Out[153]: a -2.1c 3.6e -1.5f 4.0g 3.1dtype: float64 将它们相加就会产生： 123456789In [154]: s1 + s2Out[154]: a 5.2c 1.1d NaNe 0.0f NaNg NaNdtype: float64 自动的数据对齐操作在不重叠的索引处引入了NA值。缺失值会在算术运算过程中传播。 对于DataFrame，对齐操作会同时发生在行和列上： 1234567891011121314151617181920In [155]: df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'), .....: index=['Ohio', 'Texas', 'Colorado'])In [156]: df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), .....: index=['Utah', 'Ohio', 'Texas', 'Oregon'])In [157]: df1Out[157]: b c dOhio 0.0 1.0 2.0Texas 3.0 4.0 5.0Colorado 6.0 7.0 8.0In [158]: df2Out[158]: b d eUtah 0.0 1.0 2.0Ohio 3.0 4.0 5.0Texas 6.0 7.0 8.0Oregon 9.0 10.0 11.0 把它们相加后将会返回一个新的DataFrame，其索引和列为原来那两个DataFrame的并集： 12345678In [159]: df1 + df2Out[159]: b c d eColorado NaN NaN NaN NaNOhio 3.0 NaN 6.0 NaNOregon NaN NaN NaN NaNTexas 9.0 NaN 12.0 NaNUtah NaN NaN NaN NaN 因为’c’和’e’列均不在两个DataFrame对象中，在结果中以缺省值呈现。行也是同样。 在算术方法中填充值在对不同索引的对象进行算术运算时，你可能希望当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值（比如0）： 12345678910111213141516171819202122In [165]: df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), .....: columns=list('abcd'))In [166]: df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), .....: columns=list('abcde'))In [167]: df2.loc[1, 'b'] = np.nanIn [168]: df1Out[168]: a b c d0 0.0 1.0 2.0 3.01 4.0 5.0 6.0 7.02 8.0 9.0 10.0 11.0In [169]: df2Out[169]: a b c d e0 0.0 1.0 2.0 3.0 4.01 5.0 NaN 7.0 8.0 9.02 10.0 11.0 12.0 13.0 14.03 15.0 16.0 17.0 18.0 19.0 将它们相加时，没有重叠的位置就会产生NA值： 1234567In [170]: df1 + df2Out[170]: a b c d e0 0.0 2.0 4.0 6.0 NaN1 9.0 NaN 13.0 15.0 NaN2 18.0 20.0 22.0 24.0 NaN3 NaN NaN NaN NaN NaN 使用df1的add方法，传入df2以及一个fill_value参数： 1234567In [171]: df1.add(df2, fill_value=0)Out[171]: a b c d e0 0.0 2.0 4.0 6.0 4.01 9.0 5.0 13.0 15.0 9.02 18.0 20.0 22.0 24.0 14.03 15.0 16.0 17.0 18.0 19.0 与此类似，在对Series或DataFrame重新索引时，也可以指定一个填充值： 123456In [174]: df1.reindex(columns=df2.columns, fill_value=0)Out[174]: a b c d e0 0.0 1.0 2.0 3.0 01 4.0 5.0 6.0 7.0 02 8.0 9.0 10.0 11.0 0 DataFrame和Series之间的运算跟不同维度的NumPy数组一样，DataFrame和Series之间算术运算也是有明确规定的。先来看一个具有启发性的例子，计算一个二维数组与其某行之间的差： 12345678910111213141516In [175]: arr = np.arange(12.).reshape((3, 4))In [176]: arrOut[176]: array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]])In [177]: arr[0]Out[177]: array([ 0., 1., 2., 3.])In [178]: arr - arr[0]Out[178]: array([[ 0., 0., 0., 0.], [ 4., 4., 4., 4.], [ 8., 8., 8., 8.]]) 当我们从arr减去arr[0]，每一行都会执行这个操作。这就叫做广播（broadcasting），附录A将对此进行详细讲解。DataFrame和Series之间的运算差不多也是如此： 1234567891011121314151617181920In [179]: frame = pd.DataFrame(np.arange(12.).reshape((4, 3)), .....: columns=list('bde'), .....: index=['Utah', 'Ohio', 'Texas', 'Oregon'])In [180]: series = frame.iloc[0]In [181]: frameOut[181]: b d eUtah 0.0 1.0 2.0Ohio 3.0 4.0 5.0Texas 6.0 7.0 8.0Oregon 9.0 10.0 11.0In [182]: seriesOut[182]: b 0.0d 1.0e 2.0Name: Utah, dtype: float64 默认情况下，DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列，然后沿着行一直向下广播： 1234567In [183]: frame - seriesOut[183]: b d eUtah 0.0 0.0 0.0Ohio 3.0 3.0 3.0Texas 6.0 6.0 6.0Oregon 9.0 9.0 9.0 如果某个索引值在DataFrame的列或Series的索引中找不到，则参与运算的两个对象就会被重新索引以形成并集： 123456789In [184]: series2 = pd.Series(range(3), index=['b', 'e', 'f'])In [185]: frame + series2Out[185]: b d e fUtah 0.0 NaN 3.0 NaNOhio 3.0 NaN 6.0 NaNTexas 6.0 NaN 9.0 NaNOregon 9.0 NaN 12.0 NaN 如果你希望匹配行且在列上广播，则必须使用算术运算方法。例如： 12345678910111213141516171819202122232425In [186]: series3 = frame['d']In [187]: frameOut[187]: b d eUtah 0.0 1.0 2.0Ohio 3.0 4.0 5.0Texas 6.0 7.0 8.0Oregon 9.0 10.0 11.0In [188]: series3Out[188]: Utah 1.0Ohio 4.0Texas 7.0Oregon 10.0Name: d, dtype: float64In [189]: frame.sub(series3, axis='index')Out[189]: b d eUtah -1.0 0.0 1.0Ohio -1.0 0.0 1.0Texas -1.0 0.0 1.0Oregon -1.0 0.0 1.0 传入的轴号就是希望匹配的轴。在本例中，我们的目的是匹配DataFrame的行索引（axis=’index’ or axis=0）并进行广播。 函数应用和映射NumPy的ufuncs（元素级数组方法）也可用于操作pandas对象： 123456789101112131415161718In [190]: frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'), .....: index=['Utah', 'Ohio', 'Texas', 'Oregon'])In [191]: frameOut[191]: b d eUtah -0.204708 0.478943 -0.519439Ohio -0.555730 1.965781 1.393406Texas 0.092908 0.281746 0.769023Oregon 1.246435 1.007189 -1.296221In [192]: np.abs(frame)Out[192]: b d eUtah 0.204708 0.478943 0.519439Ohio 0.555730 1.965781 1.393406Texas 0.092908 0.281746 0.769023Oregon 1.246435 1.007189 1.296221 另一个常见的操作是，将函数应用到由各列或行所形成的一维数组上。DataFrame的apply方法即可实现此功能： 12345678In [193]: f = lambda x: x.max() - x.min()In [194]: frame.apply(f)Out[194]: b 1.802165d 1.684034e 2.689627dtype: float64 这里的函数f，计算了一个Series的最大值和最小值的差，在frame的每列都执行了一次。结果是一个Series，使用frame的列作为索引。 如果传递axis=’columns’到apply，这个函数会在每行执行： 1234567In [195]: frame.apply(f, axis='columns')Out[195]:Utah 0.998382Ohio 2.521511Texas 0.676115Oregon 2.542656dtype: float64 许多最为常见的数组统计功能都被实现成DataFrame的方法（如sum和mean），因此无需使用apply方法。 传递到apply的函数不是必须返回一个标量，还可以返回由多个值组成的Series： 12345678In [196]: def f(x): .....: return pd.Series([x.min(), x.max()], index=['min', 'max'])In [197]: frame.apply(f)Out[197]: b d emin -0.555730 0.281746 -1.296221max 1.246435 1.965781 1.393406 汇总和计算描述统计pandas对象拥有一组常用的数学和统计方法。它们大部分都属于约简和汇总统计，用于从Series中提取单个值（如sum或mean）或从DataFrame的行或列中提取一个Series。跟对应的NumPy数组方法相比，它们都是基于没有缺失数据的假设而构建的。看一个简单的DataFrame： 123456789101112In [230]: df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], .....: [np.nan, np.nan], [0.75, -1.3]], .....: index=['a', 'b', 'c', 'd'], .....: columns=['one', 'two'])In [231]: dfOut[231]: one twoa 1.40 NaNb 7.10 -4.5c NaN NaNd 0.75 -1.3 调用DataFrame的sum方法将会返回一个含有列的和的Series： 12345In [232]: df.sum()Out[232]: one 9.25two -5.80dtype: float64 传入axis=’columns’或axis=1将会按行进行求和运算： 123456In [233]: df.sum(axis=1)Out[233]:a 1.40b 2.60c NaNd -0.55 NA值会自动被排除，除非整个切片（这里指的是行或列）都是NA。通过skipna选项可以禁用该功能： 1234567In [234]: df.mean(axis='columns', skipna=False)Out[234]: a NaNb 1.300c NaNd -0.275dtype: float64]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pandas学习（一）]]></title>
    <url>%2F2018%2F09%2F05%2Fpandas-1%2F</url>
    <content type="text"><![CDATA[导入 pandas、numpy、matplotlib 12345In [1]: import pandas as pdIn [2]: import numpy as npIn [3]: import matplotlib.pyplot as plt 创造对象Series 是一个值的序列，它只有一个列，以及索引。下面的例子中，就用默认的整数索引 1234567891011In [4]: s = pd.Series([1,3,5,np.nan,6,8])In [5]: sOut[5]: 0 11 32 53 NaN4 65 8dtype: float64 DataFrame 是有多个列的数据表，每个列拥有一个 label，当然，DataFrame 也有索引 1234567891011121314151617181920In [6]: dates = pd.date_range('20130101', periods=6)In [7]: datesOut[7]: DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D')In [8]: df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))#index 行名，columns，列名。都需要提供一个列表对象In [9]: dfOut[9]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-05 -0.424972 0.567020 0.276232 -1.0874012013-01-06 -0.673690 0.113648 -1.478427 0.524988 如果参数是一个 dict，每个 dict 的 value 会被转化成一个 Series 123456789101112131415In [10]: df2 = pd.DataFrame(&#123; 'A' : 1., ....: 'B' : pd.Timestamp('20130102'), ....: 'C' : pd.Series(1,index=list(range(4)),dtype='float32'), ....: 'D' : np.array([3] * 4,dtype='int32'), ....: 'E' : pd.Categorical(["test","train","test","train"]), ....: 'F' : 'foo' &#125;) ....: In [11]: df2Out[11]: A B C D E F0 1 2013-01-02 1 3 test foo1 1 2013-01-02 1 3 train foo2 1 2013-01-02 1 3 test foo3 1 2013-01-02 1 3 train foo 每列的格式用 dtypes 查看 123456789In [12]: df2.dtypesOut[12]: A float64B datetime64[ns]C float32D int32E categoryF objectdtype: object 你可以认为，DataFrame 是由 Series 组成的 1234567In [13]: df2.AOut[13]: 0 11 12 13 1Name: A, dtype: float64 查看数据用 head 和 tail 查看顶端和底端的几列 123456789101112131415In [14]: df.head()Out[14]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-05 -0.424972 0.567020 0.276232 -1.087401In [15]: df.tail(3)Out[15]: A B C D2013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-05 -0.424972 0.567020 0.276232 -1.0874012013-01-06 -0.673690 0.113648 -1.478427 0.524988 实际上，DataFrame 内部用 numpy 格式存储数据。你也可以单独查看 index 和 columns 1234567891011121314151617In [16]: df.indexOut[16]: DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D')In [17]: df.columnsOut[17]: Index(['A', 'B', 'C', 'D'], dtype='object')In [18]: df.valuesOut[18]: array([[ 0.4691, -0.2829, -1.5091, -1.1356], [ 1.2121, -0.1732, 0.1192, -1.0442], [-0.8618, -2.1046, -0.4949, 1.0718], [ 0.7216, -0.7068, -1.0396, 0.2719], [-0.425 , 0.567 , 0.2762, -1.0874], [-0.6737, 0.1136, -1.4784, 0.525 ]]) describe() 显示数据的概要。 1234567891011In [19]: df.describe()Out[19]: A B C Dcount 6.000000 6.000000 6.000000 6.000000mean 0.073711 -0.431125 -0.687758 -0.233103std 0.843157 0.922818 0.779887 0.973118min -0.861849 -2.104569 -1.509059 -1.13563225% -0.611510 -0.600794 -1.368714 -1.07661050% 0.022070 -0.228039 -0.767252 -0.38618875% 0.658444 0.041933 -0.034326 0.461706max 1.212112 0.567020 0.276232 1.071804 和 numpy 一样，可以方便的得到转置 1234567In [20]: df.TOut[20]: 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06A 0.469112 1.212112 -0.861849 0.721555 -0.424972 -0.673690B -0.282863 -0.173215 -2.104569 -0.706771 0.567020 0.113648C -1.509059 0.119209 -0.494929 -1.039575 0.276232 -1.478427D -1.135632 -1.044236 1.071804 0.271860 -1.087401 0.524988 对 axis 按照 index 排序（axis=1 是指第二个维度，即：列，axis=0 是指第一个维度，即：行） 123456789In [21]: df.sort_index(axis=1, ascending=False) #ascending=False 默认为True，升序Out[21]: D C B A2013-01-01 -1.135632 -1.509059 -0.282863 0.4691122013-01-02 -1.044236 0.119209 -0.173215 1.2121122013-01-03 1.071804 -0.494929 -2.104569 -0.8618492013-01-04 0.271860 -1.039575 -0.706771 0.7215552013-01-05 -1.087401 0.276232 0.567020 -0.4249722013-01-06 0.524988 -1.478427 0.113648 -0.673690 按值排序 123456789In [22]: df.sort_values(by='B') #也可以是by=['A','B']，按2列排序Out[22]: A B C D2013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-06 -0.673690 0.113648 -1.478427 0.5249882013-01-05 -0.424972 0.567020 0.276232 -1.087401 选择 注意，以下这些对交互式环境很友好，但是作为 production code 请用优化过的 .at, .iat, .loc, .iloc 和 .ix 获取行/列从 DataFrame 选择一个列，就得到了 Series 123456789In [23]: df['A']Out[23]: 2013-01-01 0.4691122013-01-02 1.2121122013-01-03 -0.8618492013-01-04 0.7215552013-01-05 -0.4249722013-01-06 -0.673690Freq: D, Name: A, dtype: float64 和 numpy 类似，这里也能用 []选择行 12345678910111213In [24]: df[0:3]Out[24]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.071804In [25]: df['20130102':'20130104']Out[25]: A B C D2013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.271860 通过 label 选择还可以多选 123456789In [27]: df.loc[:,['A','B']] #所有行，AB列Out[27]: A B2013-01-01 0.469112 -0.2828632013-01-02 1.212112 -0.1732152013-01-03 -0.861849 -2.1045692013-01-04 0.721555 -0.7067712013-01-05 -0.424972 0.5670202013-01-06 -0.673690 0.113648 注意那个冒号，用法和 MATLAB 或 NumPy 是一样的！所以也可以这样 123456In [28]: df.loc['20130102':'20130104',['A','B']] Out[28]: A B2013-01-02 1.212112 -0.1732152013-01-03 -0.861849 -2.1045692013-01-04 0.721555 -0.706771 12345In [29]: df.loc['20130102',['A','B']]Out[29]: A 1.212112B -0.173215Name: 2013-01-02 00:00:00, dtype: float64 如果对所有的维度都写了标量，不就是选出一个元素吗？ 如果对所有的维度都写了标量，不就是选出一个元素吗？ 12In [30]: df.loc[dates[0],'A']Out[30]: 0.46911229990718628 这种情况通常用 at ，速度更快 12In [31]: df.at[dates[0],'A']Out[31]: 0.46911229990718628 通过整数下标选择这个就和数组类似啦，直接看例子。选出第3行： 1234567In [32]: df.iloc[3]Out[32]: A 0.721555B -0.706771C -1.039575D 0.271860Name: 2013-01-04 00:00:00, dtype: float64 选出3~4行，0~1列： 12345In [33]: df.iloc[3:5,0:2] #注意 3:5 是第3行到第4行（有第0行）Out[33]: A B2013-01-04 0.721555 -0.7067712013-01-05 -0.424972 0.567020 也能用 list 选择 123456In [34]: df.iloc[[1,2,4],[0,2]]Out[34]: A C2013-01-02 1.212112 0.1192092013-01-03 -0.861849 -0.4949292013-01-05 -0.424972 0.276232 对应单个元素 1234In [37]: df.iloc[1,1]Out[37]: -0.17321464905330858In [38]: df.iat[1,1]Out[38]: -0.17321464905330858 总结：df.icol 是按下标选择，df.col是按标签选择。 通过布尔值下标基本用法 123456In [39]: df[df.A &gt; 0]Out[39]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-04 0.721555 -0.706771 -1.039575 0.271860 不满足条件的填充为： NaN 123456789In [40]: df[df &gt; 0]Out[40]: A B C D2013-01-01 0.469112 NaN NaN NaN2013-01-02 1.212112 NaN 0.119209 NaN2013-01-03 NaN NaN NaN 1.0718042013-01-04 0.721555 NaN NaN 0.2718602013-01-05 NaN 0.567020 0.276232 NaN2013-01-06 NaN 0.113648 NaN 0.524988 isin() 函数：是否在集合中 12345678910111213141516171819In [41]: df2 = df.copy()In [42]: df2['E'] = ['one', 'one','two','three','four','three']In [43]: df2Out[43]: A B C D E2013-01-01 0.469112 -0.282863 -1.509059 -1.135632 one2013-01-02 1.212112 -0.173215 0.119209 -1.044236 one2013-01-03 -0.861849 -2.104569 -0.494929 1.071804 two2013-01-04 0.721555 -0.706771 -1.039575 0.271860 three2013-01-05 -0.424972 0.567020 0.276232 -1.087401 four2013-01-06 -0.673690 0.113648 -1.478427 0.524988 threeIn [44]: df2[df2['E'].isin(['two','four'])]Out[44]: A B C D E2013-01-03 -0.861849 -2.104569 -0.494929 1.071804 two2013-01-05 -0.424972 0.567020 0.276232 -1.087401 four 读取、写入数据CSV写入 1In [136]: df.to_csv('foo.csv') 读取 12345678In [137]: pd.read_csv('foo.csv')In [137]: pd.read_csv(StringIO(data), names=['foo', 'bar', 'baz'], header=None)# 自定义表头，当name设定的时候，header必须显式None，因为默认为0 foo bar baz0 a b c1 1 2 32 4 5 63 7 8 9 table读取 12data = pd.read_table('example.txt',sep='\t',header=0) # 指定分隔符和表头，默认header=0，把第一行作为表头。分割符默认制表符'/t'，'/s+'，可以匹配任何空格。 excel写入 1In [140]: df.to_excel('foo.xlsx', sheet_name='Sheet1') 读取 12In [141]: pd.read_excel('foo.xlsx', sheet_name='Sheet1', index_col=None, na_values=['NA'])#index_col 行名，na_values 缺失值的形式]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[next主题设置]]></title>
    <url>%2F2018%2F09%2F01%2Fnext-theme%2F</url>
    <content type="text"><![CDATA[主题风格通过修改next主题下的_config.yml的scheme字段，配置不同的风格。 12345# Schemes#scheme: Musescheme: Mist #推荐#scheme: Pisces#scheme: Gemini 菜单通过修改next主题下的_config.yml的menu字段，选定显示的菜单项。 可自己修改字段和目录名，||之后为配套的小图标。我添加了links字段，但是当前语言是简体中文，页面上无法给我翻译出来，去添加language/zh-CN.yml里的对应字段即可。 1234567menu: home: /home/ || home about: /about/ || user #tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive links: /links/ || calendar 头像在主题下的source/images/下替换原有的头像文件avatar.gif，并在_config.yml中查找Sidebar Avatar字段，添加url字段内容： /images/avatar.gif 头像旋转找到位于 source/css/_common/components/sidebar/sidebar-author.syl 模板文件里侧边栏头像的样式 .site-author-image 将内容修改为 123456.site-author-image &#123; border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; transition: 1.4s all;&#125; 然后添加 .site-author-image:hover 样式，由 rotate() 方法实现，旋转 360° 123456.site-author-image:hover &#123; -webkit-transform: rotate(360deg); -moz-transform: rotate(360deg); -ms-transform: rotate(360deg); -transform: rotate(360deg);&#125; 文章代码主题Next主题总共支持5种主题，默认主题是白色的normal。通过修改next主题下的_config.yml的highlight字段，来设置代码主题。 推荐 night 。 标签、分类在存在标签页、分类页的情况下，在写文章的时候，在文章头部添加 tags、categories 字段。 12tags: [npm, hexo, github]categories: 搭建博客 搜索功能安装 hexo-generator-searchdb 1$ npm install hexo-generator-searchdb --save 在站点myBlog/_config.yml中添加search字段，如下 12345search:path: search.xmlfield: postformat: htmllimit: 10000 修改next主题下的_config.yml的Local search字段 1enable: true hexo博客底部页脚找到/themes/next/layout/_partials/footer.swig文件 内容如下 1234567891011121314151617181920&lt;div class="copyright" &gt; &#123;% set current = date(Date.now(), "YYYY") %&#125; © &#123;% if theme.since and theme.since != current %&#125; &#123;&#123; theme.since &#125;&#125; - &#123;% endif %&#125; &lt;span itemprop="copyrightYear"&gt;&#123;&#123; current &#125;&#125;&lt;/span&gt; &lt;span class="with-love"&gt; &lt;i class="fa fa-heart"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class="author" itemprop="copyrightHolder"&gt;&#123;&#123; config.author &#125;&#125;&lt;/span&gt;&lt;/div&gt;&lt;div class="powered-by"&gt; &#123;&#123; __('footer.powered', '&lt;a class="theme-link" href="https://hexo.io"&gt;Hexo&lt;/a&gt;') &#125;&#125;&lt;/div&gt;&lt;div class="theme-info"&gt; &#123;&#123; __('footer.theme') &#125;&#125; - &lt;a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"&gt; NexT.&#123;&#123; theme.scheme &#125;&#125; &lt;/a&gt;&lt;/div&gt; 删除class 为powered-by的div和theme-info的div。 github标识在网站上选择一个喜欢的标识类型，复制粘贴代码到themes/next/layout/_layout.swig文件中(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下面)，并把href改为个人github地址 。 首页隐藏指定文章有时候我们可能只想在首页显示关于编程之类的内容，而个人日记之类的文章放在其他分类之下而不在首页显示。可以从、分类、标签、归档中查看文章。 自定义front-matter的参数例如，自定义添加一个notshow参数，值为true，用来提供判断 123tags: [npm, hexo, github]categories: 搭建博客notshow: true 修改主题的themes/next/layout/index.swig文件,将 123456789&#123;% block content %&#125; &lt;section id="posts" class="posts-expand"&gt; &#123;% for post in page.posts %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endfor %&#125; &lt;/section&gt; &#123;% include '_partials/pagination.swig' %&#125;&#123;% endblock % 添加过滤条件 1234567891011&#123;% block content %&#125; &lt;section id="posts" class="posts-expand"&gt; &#123;% for post in page.posts %&#125; &#123;% if post.notshow != true %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;/section&gt; &#123;% include '_partials/pagination.swig' %&#125;&#123;% endblock %&#125;]]></content>
      <categories>
        <category>折腾</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python-copy]]></title>
    <url>%2F2018%2F08%2F27%2Fpython-copy%2F</url>
    <content type="text"><![CDATA[赋值（assignment）在Python中，用一个变量给另一个变量赋值，其实就是给当前内存中的对象增加一个“标签”而已。 12345&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; print(id(a), id(b), sep='\n') #a和b都只是[1,2,3]的一个标签139701469405552139701469405552 浅拷贝（shallow copy）注意：浅拷贝和深拷贝的不同仅仅是对组合对象来说，所谓的组合对象就是包含了其它对象的对象，如列表，类实例。而对于数字、字符串以及其它“原子”类型，没有拷贝一说，产生的都是原对象的引用。 所谓“浅拷贝”，是指创建一个新的对象，其内容是原对象中元素的引用。（拷贝组合对象，不拷贝子对象） 常见的浅拷贝有：切片操作、工厂函数（如list()，dict()等）、对象的copy()方法、copy模块中的copy函数。 12345678910&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = list(a)&gt;&gt;&gt; print(id(a), id(b)) # a和b身份不同140601785066200 140601784764968&gt;&gt;&gt; for x, y in zip(a, b): # 但它们包含的子对象身份相同... print(id(x), id(y))... 140601911441984 140601911441984140601911442016 140601911442016140601911442048 140601911442048 从上面可以明显的看出来，a 浅拷贝得到 b，a 和 b 指向内存中不同的 list 对象，但它们的元素却指向相同的 int 对象。这就是浅拷贝！ 1234567&gt;&gt;&gt; a = [1, 2, 3，[4,5]]&gt;&gt;&gt; b = list(a)&gt;&gt;&gt; a[-1].append(6)&gt;&gt;&gt; print(a)[1, 2, 3，[4,5,6]]&gt;&gt;&gt; print(b) #当a的子对象发生改变时，b也发生了改变[1, 2, 3，[4,5,6]] 深拷贝（deep copy）所谓“深拷贝”，是指创建一个新的对象，然后递归的拷贝原对象所包含的子对象。深拷贝出来的对象与原对象没有任何关联。 深拷贝只有一种方式：copy模块中的deepcopy函数。 12345678&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3，[4,5]]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; a[-1].append(6)&gt;&gt;&gt; print(a)[1, 2, 3，[4,5,6]]&gt;&gt;&gt; print(b) #当a的子对象发生改变时，b不发生改变[1, 2, 3，[4,5]] 1234567891011&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; print(id(a), id(b))140601785065840 140601785066200&gt;&gt;&gt; for x, y in zip(a, b):... print(id(x), id(y))... 140601911441984 140601911441984140601911442016 140601911442016140601911442048 140601911442048 看了上面的例子，有人可能会疑惑： 为什么使用了深拷贝，a和b中元素的id还是一样呢？ 答：这是因为对于不可变对象，当需要一个新的对象时，python可能会返回已经存在的某个类型和值都一致的对象的引用。而且这种机制并不会影响 a 和 b 的相互独立性，因为当两个元素指向同一个不可变对象时，对其中一个赋值不会影响另外一个。 我们可以用一个包含可变对象的列表来确切地展示“浅拷贝”与“深拷贝”的区别： 1234567891011121314151617181920&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [[1, 2],[5, 6], [8, 9]]&gt;&gt;&gt; b = copy.copy(a) # 浅拷贝得到b&gt;&gt;&gt; c = copy.deepcopy(a) # 深拷贝得到c&gt;&gt;&gt; print(id(a), id(b)) # a 和 b 不同139832578518984 139832578335520&gt;&gt;&gt; for x, y in zip(a, b): # a 和 b 的子对象相同... print(id(x), id(y))... 139832578622816 139832578622816139832578622672 139832578622672139832578623104 139832578623104&gt;&gt;&gt; print(id(a), id(c)) # a 和 c 不同139832578518984 139832578622456&gt;&gt;&gt; for x, y in zip(a, c): # a 和 c 的子对象也不同... print(id(x), id(y))... 139832578622816 139832578621520139832578622672 139832578518912139832578623104 139832578623392 总结：1、赋值：简单地拷贝对象的引用，两个对象的id相同。2、浅拷贝：创建一个新的组合对象，这个新对象与原对象共享内存中的子对象。3、深拷贝：创建一个新的组合对象，同时递归地拷贝所有子对象，新的组合对象与原对象没有任何关联。虽然实际上会共享不可变的子对象，但不影响它们的相互独立性。 浅拷贝和深拷贝的不同仅仅是对组合对象来说，所谓的组合对象就是包含了其它对象的对象，如列表，类实例。而对于数字、字符串(如a=1)以及其它“原子”类型，没有拷贝一说，产生的都是原对象的引用。]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ruby-re]]></title>
    <url>%2F2018%2F08%2F21%2Fruby-re%2F</url>
    <content type="text"><![CDATA[Ruby中正则表达式的写法主要有三种 在//之间，要进行转义 在%r{}内，不用进行转义 Regexp.new()内，不用进行转义 匹配的两种方法 =~肯定匹配, !~否定匹配。=~表达式返回匹配到的位置索引，失败返回nil，符号左右内容可交换 regexp#match(str)，返回MatchData，一个数组，从0开始，还有match.pre_match返回匹配前内容，match.post_match返回匹配后内容 1234/cat/ =~ "dog and cat" #返回8# 类似python可以将正则放入一个变量，如re = Regexp.new(/cat/)，在后续匹配时直接使用remt = /cat/.match("bigcatcomes") # mt = re.match("bigcatcomes")"#&#123;mt.pre_match&#125;-&gt;#&#123;mt[0]&#125;&lt;-#&#123;mt.post_match&#125;" #返回big-&gt;cat&lt;-comes 替换很多时候匹配是为了替换，Ruby中进行正则替换非常简单，两个方法即可搞定，sub()+gsub()。sub只替换第一次匹配，gsub（g:global）会替换所有的匹配，没有匹配到返回原字符串的copy 123str = "ABDADA"new_str = str.sub(/A/, "a") #返回"aBDADA"new_str2 = str.gsub(/A/, "a") #返回"aBDaDa" 分组匹配Ruby的分组匹配与其它语言差别不大，分组匹配表达式是对要进行分组的内容加()。对于匹配到的结果，可以用系统变量$1，$2…索引，也可用matchData数组来索引 123md = /(\d\d):(\d\d)(..)/.match("12:50am") # md为一个MatchData对象puts "Hour is #&#123;$1&#125;, minute #&#123;$2&#125;"puts "Hour is #&#123;md[1]&#125;, minute #&#123;md[2]&#125;" 匹配所有regexp#match()只能匹配一次，如果想匹配所有要用regexp#scan()用法示例： 1"abcabcqwe".scan(%r&#123;abc&#125;).each &#123;|x| puts x&#125; # 输出2行abc]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo+github搭建博客]]></title>
    <url>%2F2018%2F08%2F09%2Fhexo%2Bgithub%2F</url>
    <content type="text"><![CDATA[准备node.js和git node.js : 直接官网下载 git : 直接官网下载 验证安装结果 : 1234$ node -v$ npm -v#npm是随同NodeJS一起安装的包管理工具,类似python的pip$ git --version Github账户注册和新建项目项目必须要遵守格式：uername.github.io，如下： 安装Hexo Hexo 是一个快速、简洁且高效的博客框架。 12345$ mkdir blog &amp;&amp; cd - #创建个人目录$ npm install -g hexo-cli #安装hexo$ hexo -v #检查hexo$ hexo init #初始化hexo$ npm install #安装所需包 Hexo与Github page关联 设置Git的user name和email（如果是第一次的话） 12git config --global user.name "xxx" git用户名git config --global user.email "xxx@xx.com" git邮箱 生成密钥、公钥 1234$ ssh-add -D$ rm -r ~/.ssh #删除存在的密钥、公钥$ ssh-keygen -t rsa -C "xxx@xx.com" #生成新密钥、公钥对应git邮箱$ cat ~/.ssh/id_rsa.pub #查看公钥内容 添加公钥到github 登陆github帐户，点击头像，然后 Settings -&gt; 左栏点击 SSH and GPG keys -&gt; 点击 New SSH key。然后复制上面的公钥内容，粘贴进“Key”文本域内。 title随便起个名字，点击 Add key完成。 确认成功 1234$ ssh -T xxx@github.com$ git remote -vorigin https://github.com/someaccount/someproject.git (fetch)origin https://github.com/someaccount/someproject.git (push) git使用https协议，每次pull, push都会提示要输入密码，使用git协议，然后使用ssh密钥，这样免去每次都输密码的麻烦。 SSH地址 HTTPS地址 在_config.yml 进行基础配置回到创建hexo的文件夹找到_config.yml，并编辑最后的信息: 12345deploy： type： git repository ：git@github.com:flystar233/flystar233.github.io.git #发布不再需要密码 repository ：https://github.com/flystar233/flystar233.github.io.git #发布需要密码 branch ：master 让博客能加载图片12post_asset_folder: true #在_config.yml中将false改为true$ npm install hexo-asset-image --save #在命令行中执行 这样之后，在运行hexo n &quot;xxxx&quot;来生成md博客时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹。将博客所需图片放入此文件夹中，在md文件中（博客内容）插入图片时，使用命令![](xxxx/pic.png)#md插入图片公式 来插入图片，xxxx是文件夹的名字，路径不可有中文。 发布博客在生成以及部署文章之前，需要安装一个扩展： 1$ npm install hexo-deployer-git --save 发布相关命令 123456$ hexo clean # 清除全部文章$ hexo generate == hexo g #生成静态文件$ hexo deploy == hexo d #部署文件到github$ hexo new "文件名" #创建新文章$ hexo new page "页面名" #创建新页面$ hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server） 查看博客 部署成功后访问博客地址，如：flystar233.github.io]]></content>
      <categories>
        <category>折腾</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[awk]]></title>
    <url>%2F2018%2F08%2F08%2Fawk%2F</url>
    <content type="text"><![CDATA[使用awk 取文件第一列是以数字开头的数据： 1awk '$1~/^[0-9]+/ &#123;print $0&#125;' infile &gt; outfile 使用awk 取文件第一列包含chr或者包含sca： 1awk '$1~/chr|sca/ &#123;print $0&#125;' infile &gt; outfile 使用awk 取文件第一列大于0.1且小于0.5的数据： 1awk '$1&gt;0.1 &amp;&amp; $1&lt;0.5 &#123;print $0&#125;' infile &gt; outfile 使用awk 取文件第一列是chr： 12awk '$1~/^chr$/ &#123;print $0&#125;' infile &gt; outfileawk '$1=="chr" &#123;print $0&#125;' infile &gt; outfile]]></content>
      <categories>
        <category>代码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[world]]></title>
    <url>%2F2018%2F08%2F07%2Fworld%2F</url>
    <content type="text"><![CDATA[要了解世界的概念就要不断的减少个体的差异性。 我们知道人生而不同，但是要在脑海中形成对世界的认识，就要减少对相同类不同个体的存在，然后逐渐逼近对世界的正确认识。 世界是人在运行的么？不是。人只是世界很小的一个产物，人的主观能动性使人类科技，社会发展，那么人已经拥有可以控制世界的能力了么？小点说，人类已经拥有可以控制地球的能力了么？没有。人类在不断的进步中，还是在顺应自然的变化。 世界是太阳运行的么？不是。太阳为地球所有的生物提供了生存的条件：能量，万物生长，在地球上形成自然环境。那么，太阳会消失么？会的，太阳不断地核聚变产生能量，也在不断的泯灭，终有一天，太阳不在发出光芒，如果人类没有最终造出太阳的替代品，那么地球也将会消失。那么世界不再运行了么？没有。太阳系在已知宇宙中小的就像沧海一粟，一块皮肤老了，掉了也无所谓。 世界是光运行的么？只能说，光是一个必要不充分条件。没有光，世界万物无法生长，世界没有生机，没有了活力，没有了发展的动力。然而，没有光世界还在运行，宇宙深处没有光线，只有天体，他们依然按照旋转规律不停地运动，如果你觉得没有光，怎么知道有天体在动，那你可以做个小小的实验：找一个不透光的长盒子，两端开口，把一个小球扔进去，那么一定会在另一端小球出来。你看见小球在里边的运动了么？没有。你知道小球在动么？知道。 世界根本没有事物在操纵运行，完全是按照无序的规律自我运行的么？不知道，最起码现在不知道。我们不能把一切无法了解的事物归于神。神是什么？在外人解释来说，神就是唯心主义，是精神。谁也没见过神，是神造人？还是人造神？…]]></content>
      <categories>
        <category>文字</category>
      </categories>
  </entry>
</search>
