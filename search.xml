<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[R 字符串处理]]></title>
    <url>%2F2018%2F10%2F18%2FR-stringr%2F</url>
    <content type="text"><![CDATA[使用R包stringr进行R语言的字符串处理。 str_count()计算字符串中字符个数。 1234&gt; library(stringr)&gt; fruit &lt;- c("apple", "banana", "pear", "pineapple")&gt; str_count(fruit, "a")#&gt; [1] 1 3 1 1 str_detect()检查字符是否在字符串中。 12345&gt; fruit &lt;- c("apple", "banana", "pear", "pinapple")&gt; str_detect(fruit, "a")#&gt; [1] TRUE TRUE TRUE TRUE&gt; str_detect(fruit, "^a")#&gt; [1] TRUE FALSE FALSE FALSE str_extract()模式匹配。 123456789&gt; shopping_list &lt;- c("apples x4", "bag of flour", "bag of sugar", "milk x2")&gt; str_extract_all(shopping_list, "[a-z]+\\b", simplify = TRUE) #simplify = TRUE 以矩阵的方式展示结果#&gt; [,1] [,2] [,3] #&gt; [1,] "apples" "" "" #&gt; [2,] "bag" "of" "flour"#&gt; [3,] "bag" "of" "sugar"#&gt; [4,] "milk" "" "" &gt; str_extract(shopping_list, "[a-z]+\\b")[1] "apples" "bag" "bag" "milk" str_match ()模式匹配，进行分组匹配。 12345&gt; fruit &lt;- c("apple12345679!123")&gt; str_match_all(fruit,"([a-z]+).*?(!)") #分2个组，结果第一个为全部匹配的结果[[1]] [,1] [,2] [,3][1,] "apple12345679!" "apple" "!" str_locate()模式匹配位置。 12345678910111213141516171819202122232425262728293031&gt; fruit &lt;- c("apple", "banana", "pear", "pineapple") &gt; str_locate(fruit, "a")#&gt; start end#&gt; [1,] 1 1#&gt; [2,] 2 2#&gt; [3,] 3 3#&gt; [4,] 5 5&gt; str_locate(fruit, c("a", "b", "p", "p"))#&gt; start end#&gt; [1,] 1 1#&gt; [2,] 1 1#&gt; [3,] 1 1#&gt; [4,] 1 1&gt; str_locate_all(fruit, "a")[[1]] start end[1,] 1 1[[2]] start end[1,] 2 2[2,] 4 4[3,] 6 6[[3]] start end[1,] 3 3[[4]] start end[1,] 5 5 str_subset()功能如 linux下grep。 1234567&gt; fruit &lt;- c("apple", "banana", "pear", "pinapple")&gt; str_subset(fruit, "a")#&gt; [1] "apple" "banana" "pear" "pinapple"&gt; str_subset(fruit, "^a")#&gt; [1] "apple"&gt; str_subset(fruit, "[aeiou]")#&gt; [1] "apple" "banana" "pear" "pinapple" str_replace()替换字符。 12345&gt; fruits &lt;- c("one apple", "two pears", "three bananas")&gt; str_replace(fruits, "[aeiou]", "-")#&gt; [1] "-ne apple" "tw- pears" "thr-e bananas"&gt; str_replace_all(fruits, "[aeiou]", "-")#&gt; [1] "-n- -ppl-" "tw- p--rs" "thr-- b-n-n-s" str_split()分割字符串。 12345678910111213141516171819&gt; fruits &lt;- c( "apples and oranges and pears and bananas", "pineapples and mangos and guavas")&gt; str_split(fruits, " and ")#&gt; [[1]]#&gt; [1] "apples" "oranges" "pears" "bananas" #&gt; [[2]]#&gt; [1] "pineapples" "mangos" "guavas" &gt; str_split(fruits, " and ", simplify = TRUE)#&gt; [,1] [,2] [,3] [,4] #&gt; [1,] "apples" "oranges" "pears" "bananas"#&gt; [2,] "pineapples" "mangos" "guavas" "" &gt; str_split(fruits, " and ", n = 3)#&gt; [[1]]#&gt; [1] "apples" "oranges" "pears and bananas" #&gt; [[2]]#&gt; [1] "pineapples" "mangos" "guavas" str_sort()字符串排序。 12345678910&gt; letter&lt;-c('an apple','two oranges','three bananas','four tomatoes')&gt; str_sort(letter)[1] "an apple" "four tomatoes" "three bananas" "two oranges"&gt; str_sort(letter,decreasing = TRUE)[1] "two oranges" "three bananas" "four tomatoes" "an apple"x &lt;- c("100a10", "100a5", "2b", "2a")str_sort(x)#&gt; [1] "100a10" "100a5" "2a" "2b" str_sort(x, numeric = TRUE)#&gt; [1] "2a" "2b" "100a5" "100a10" str_to_upper() str_to_lower() str_to_title()改变字符大小写。 str_length()字符串长度。 str_c()拼接字符串。 1234&gt; str_c('I have',letter,sep = ' ') #单字符串加字符[1] "I have an apple" "I have two oranges" "I have three bananas" "I have four tomatoes"&gt; str_c(letter,collapse = ',')[1] "an apple,two oranges,three bananas,four tomatoes" #拼接所有字符串]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[R 数据处理]]></title>
    <url>%2F2018%2F10%2F02%2FR-data-progress%2F</url>
    <content type="text"><![CDATA[本节函数都来自于dplyr包，都可以和group_by函数联合起来处理复杂的数据。 filterfilter()函数用来根据列的具体数据选择行。 12345678910111213141516171819&gt; library(dplyr)&gt; names(mpg) "manufacturer" "model" "displ" "year" "cyl" "trans" "drv" "cty" "hwy" "fl" "class"&gt; filter(mpg,year==1999) #选择year==1999的数据# A tibble: 117 x 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 1.80 1999 4 auto(l5) f 18 29 p compact 2 audi a4 1.80 1999 4 manual(m5) f 21 29 p compact 3 audi a4 2.80 1999 6 auto(l5) f 16 26 p compact&gt; filter(mpg,year==1999,displ&gt;5) #选择year==1999且displ&gt;5的数据# A tibble: 16 x 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 chevrolet c1500 suburban 2wd 5.70 1999 8 auto(l4) r 13 17 r suv 2 chevrolet corvette 5.70 1999 8 manual(m6) r 16 26 p 2seater 3 chevrolet corvette 5.70 1999 8 auto(l4) r 15 23 p 2seater 4 chevrolet k1500 tahoe 4wd 5.70 1999 8 auto(l4) 4 11 15 r suv 5 chevrolet k1500 tahoe 4wd 6.50 1999 8 auto(l4) 4 14 17 d suv arrangearrange()函数用来排列行的顺序。 12345678910111213141516&gt; arrange(mpg,year,cty, hwy) #根据year,cty, hwy进行行排序# A tibble: 234 x 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 chevrolet k1500 tahoe 4wd 5.70 1999 8 auto(l4) 4 11 15 r suv 2 dodge dakota pickup 4wd 5.20 1999 8 auto(l4) 4 11 15 r pickup 3 dodge durango 4wd 5.90 1999 8 auto(l4) 4 11 15 r suv &gt; arrange(mpg,year,cty, hwy) #根据year,cty, hwy进行行排序&gt; arrange(mpg,desc(year)) #根据year进行行降序排序# A tibble: 234 x 11 manufacturer model displ year cyl trans drv cty hwy fl class &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 2.00 2008 4 manual(m6) f 20 31 p compact 2 audi a4 2.00 2008 4 auto(av) f 21 30 p compact 3 audi a4 3.10 2008 6 auto(av) f 18 27 p compact 4 audi a4 quattro 2.00 2008 4 manual(m6) 4 20 28 p compact selectselect()函数用来选择列。 1234567&gt; select(mpg,year,cty, hwy) #只显示year,cty, hwy三列# A tibble: 234 x 3 year cty hwy &lt;int&gt; &lt;int&gt; &lt;int&gt; 1 1999 18 29 2 1999 21 29 3 2008 20 31 select()函数的辅助函数： start_with(&quot;abc&quot;) ：匹配以 “abc” 开头的变量名。 ends_with(&quot;xyz&quot;) ：以 “xyz” 结尾。 contains(&quot;ijk&quot;) ：包含 “ijk”。 match(&quot;(.)\\\1&quot;) ：正则匹配重复字符。 num_range(&quot;x&quot;,1:3) ：匹配x1，x2和x3。 renamerename()用来改变变量名。 1&gt; rename(mpg,YEAR=year) #将year重命名YEAR mutatemutate()函数用来对数据进行增加新列。 1234567891011121314&gt; mutate(mpg,cty2=cty*2) #数值型# A tibble: 234 x 12 manufacturer model displ year cyl trans drv cty hwy fl class cty2 &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; 1 audi a4 1.80 1999 4 auto(l5) f 18 29 p compact 36. 2 audi a4 1.80 1999 4 manual(m5) f 21 29 p compact 42. 3 audi a4 2.00 2008 4 manual(m6) f 20 31 p compact 40.&gt; mutate(mpg,cty2=paste(drv,cty,sep = "")) #字符型# A tibble: 234 x 12 manufacturer model displ year cyl trans drv cty hwy fl class cty2 &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; 1 audi a4 1.80 1999 4 auto(l5) f 18 29 p compact f18 2 audi a4 1.80 1999 4 manual(m5) f 21 29 p compact f21 3 audi a4 2.00 2008 4 manual(m6) f 20 31 p compact f20]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[R 分面]]></title>
    <url>%2F2018%2F10%2F02%2FR-facet%2F</url>
    <content type="text"><![CDATA[有时候会有需求需要把一个数据框的数据作图，再按照不同的分类将图形分开绘制。或者，只是需要把2个或者多个图简单地放在一个画布上，R图的分面将会作用与此。 facet_gridggplot2的facet_grid()函数按分类条件将图形在行或者列上分面绘图。 1234567&gt; p &lt;- ggplot(mpg, aes(displ, cty)) + geom_point()&gt; p + facet_grid(rows = vars(drv)) #按行分面&gt; p + facet_grid(cols = vars(cyl)) #按列分面&gt; p + facet_grid(vars(drv), vars(cyl)) #使用2个变量同时在行列分面&gt; mt &lt;- ggplot(mtcars, aes(mpg, wt, colour = factor(cyl))) +geom_point() #按cyl填充颜色&gt; mt + facet_grid(cols = vars(cyl), scales = "free") #scales = "free"刻度在在分面上可自适应 facet_wrapggplot2的facet_wrap()函数按分类条件将图形2d(默认n x n)形式的铺在画布上。 123456&gt; p &lt;- ggplot(mpg, aes(displ, hwy)) + geom_point()&gt; p + facet_wrap(vars(class)) #按class分面&gt; p + facet_wrap(vars(class), nrow = 4) #强制分为4行&gt; p + facet_wrap(vars(class), ncol = 4) #强制分为4列&gt; p + facet_wrap(vars(cyl, drv)) #使用2个变量进行分类&gt; p + facet_wrap(c("cyl", "drv"), labeller = "label_both") #友好的显示分类变量名 grid.arrangegrid.arrange()是gridExtra包的一个函数，可以将多个图放入一个画布中。 12345678&gt; install.packages("gridExtra")&gt; library(gridExtra)&gt; p1&lt;-ggplot(mpg, aes(displ, hwy)) + geom_point()&gt; p2&lt;-ggplot(mpg, aes(displ, hwy)) + geom_point()&gt; p3&lt;-ggplot(mpg, aes(displ, hwy)) + geom_point()&gt; grid.arrange(p1,p2,p3, nrow=2) #设定为2行图形&gt; grid.arrange(p1,p2,p3, nrow=2,top = textGrob("xxx",gp=gpar(col="red",fontsize=20，font=2))) #设置总标题，并修改颜色大小，字体]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[R 回归分析]]></title>
    <url>%2F2018%2F09%2F29%2FR-regression-analysis%2F</url>
    <content type="text"><![CDATA[逐步回归逐步回归分析是以AIC信息统计量为准则，通过选择最小的AIC信息统计量，来达到删除或增加变量的目的。 AIC : 赤池信息准则(Akaike Information Criterion) ,k是模型中估计参数的数量。L是模型的似然函数的最大值。 AICc：当样本量很小时，AIC很可能会选择具有太多参数的模型，即AIC会过度拟合。为了解决这种潜在的过度拟合问题，AICc可以对小样本进行校正。其中n表示样本大小，k表示参数的数量。 向前逐步回归首先模型中只有一个单独解释因变量变异最大的自变量，之后尝试将加入另一自变量，看加入后整个模型所能解释的因变量变异是否显著增加（这里需要进行检验，可以用 F-test， t-test 等等）。这一过程反复迭代，直到没有自变量再符合加入模型的条件。 MASS包中的stepAIC()函数给予AIC准则实现了逐步回归模型（向前、向后和双向）。 123&gt; library(MASS)&gt; fit &lt;- lm(xx ~ x+y+z,data=datas)&gt; stepAIC(fit, direction="forward") 向后逐步回归向后逐步回归与向前逐步回归相反，此时，所有变量均放入模型，之后尝试将其中一个自变量从模型中剔除，看整个模型解释因变量的变异是否有显著变化，之后将使解释量减少最少的变量剔除；此过程不断迭代，直到没有自变量符合剔除的条件。 123&gt; library(MASS)&gt; fit &lt;- lm(xx ~ x+y+z,data=datas)&gt; stepAIC(fit, direction="backward") 向前向后逐步回归向前向后逐步回归，这种方法相当于将前两种结合起来。可以想象，如果采用第一种方法，每加入一个自变量，可能会使已存在于模型中的变量单独对因变量的解释度减小，当其的作用很小（不显著）时，则可将其从模型中剔除。而第三种方法就做了这么一件事，不是一味的增加变量，而是增加一个后，对整个模型中的所有变量进行检验，剔除作用不显著的变量。最终尽可能得到一个最优的变量组合。 123&gt; library(MASS)&gt; fit &lt;- lm(xx ~ x+y+z,data=datas)&gt; stepAIC(fit, direction="both") Forward、Backward、Stepwise的侧重点有所不同，三种方法的选择取决于你的研究目的，如果是进行预测，在预测效果差不多的情况下，一般选择自变量最少的方法。当自变量间不存在多重共线性时，三种方法的计算结果基本一致。当自变量间存在多重共线性时，Forward侧重于引入单独作用较强的变量，Backward侧重于引入联合作用较强的变量，Stepwise介于两者之间。 全子集回归全子集回归克服了逐步回归的缺点，即所有可能的模型都会被检验，评判准则可以是R平方、修正R平方、BIC或者Mallows Cp统计量。 R平方： 修正R平方 : 我们知道在其他变量不变的情况下，引入新的变量，总能提高模型的R2。修正R2就是相当于给变量的个数加惩罚项。换句话说，如果两个模型，样本数一样，R2一样，那么从修正R2的角度看，使用变量个数少的那个模型更优。其中n是样本数量，p是模型中变量的个数。 当p/n值很小时，如小于0.05，修正R平方将失去修正作用。 BIC：贝叶斯信息准则 ，BIC的惩罚项比AIC的大，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高。 Mallows Cp：马洛斯的Cp值 与AIC等效。 以下为R中ISLR包的Hitters数据集为例，构建棒球运动员的多元线性模型 。 12345678910111213141516171819202122232425&gt; library(ISLR)&gt; library(leaps) #使用leaps做全子集回归&gt; Hitters &lt;- na.omit(Hitters)&gt; dim(Hitters) #除去Salary做为因变量，还剩下19个特征[1] 263 20&gt; regfit.full = regsubsets(Salary~.,Hitters,nvmax = 19) #选择最大19个特征的全子集选择模型&gt; reg.summary = summary(regfit.full) # 可看到不同数量下的特征选择&gt; plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted R2",type = "l")&gt; points(which.max(reg.summary$adjr2),reg.summary$adjr2[11],col="red",cex=2,pch=20) #11个特征时，Adjusted R2最大&gt; plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type = "l")&gt; points(which.min(reg.summary$cp),reg.summary$cp[10],col="red",cex=2,pch=20) # 10个特征时，Cp最小&gt; plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type = "l")&gt; points(which.min(reg.summary$bic),reg.summary$bic[6],col="red",cex=2,pch=20) # 6个特征时，BIC最小&gt; plot(regfit.full,scale = "r2") #特征越多，R2越大，这不意外，默认scale是bic。&gt; plot(regfit.full,scale = "adjr2") #下图&gt; coef(regfit.full,11) #查看模型的系数 (Intercept) AtBat Hits Walks CAtBat 135.7512195 -2.1277482 6.9236994 5.6202755 -0.1389914 CRuns CRBI CWalks LeagueN DivisionW 1.4553310 0.7852528 -0.8228559 43.1116152 -111.1460252 PutOuts Assists 0.2894087 0.2688277 交叉验证交叉验证是在机器学习建立模型和验证模型参数时常用的办法，一般被用于评估一个机器学习模型的表现。更多的情况下，也用交叉验证来进行模型选择(model selection)。 k重交叉验证中，样本被分为k个子样本，轮流将k-1个子样本组合作为训练集，另外1个子样本作为测试集，这样会获得k个预测方程，记录k个测试样本的预测表现结果，然后求其平均值。测试集的目的简单来说就相当于一个游戏的内测，内部评估。进行交叉验证后得到了分数来评估你建模的准确率是高是低。最后的目的是为了哪天来了新的数据，你也可以用你的模型去预测他，相当于游戏公测。 bootstrap包中的crossval() 函数可实现k重交叉验证 ： 1234567891011121314151617181920212223&gt; install.packages("bootstrap") &gt; library(bootstrap) &gt; shrinkage&lt;-function(fit,k=10)&#123; require(bootstrap) theta.fit&lt;-function(x,y)&#123;lsfit(x,y)&#125; theta.predict&lt;-function(fit,x)&#123;cbind(1,x)%*%fit$coef&#125; x&lt;-fit$model[,2:ncol(fit$model)] y&lt;-fit$model[,1] results&lt;-crossval(x,y,theta.fit,theta.predict,ngroup=k) r2&lt;-cor(y,fit$fitted.values)^2 r2cv&lt;-cor(y,results$cv.fit)^2 cat("Original R-square=",r2,"n") cat(k,"Fold Cross-Validated R-square=",r2cv,"n") cat("Change=",r2-r2cv,"n") &#125; &gt; fit&lt;-lm(Murder ~ Population+Income+Illiteracy+Frost,data=states) &gt; shrinkage(fit) &gt; fit2&lt;-lm(Murder ~ Population+Illiteracy,data=states) &gt; shrinkage(fit2) Original R-square=0.566832710 Fold Cross-Validated R-square=0.5193801Change=0.04745256]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[R 数据预处理]]></title>
    <url>%2F2018%2F09%2F28%2Fdeal-with-r-data%2F</url>
    <content type="text"><![CDATA[将若干向量组合为数据框12345678&gt; g &lt;- c("a","b","c")&gt; x &lt;- 1:3&gt; data &lt;- data.frame(g,x)&gt; data g x1 a 12 b 23 c 3 从数据框中提取摘要信息1234&gt; str(data)'data.frame': 3 obs. of 2 variables: $ g: Factor w/ 3 levels "a","b","c": 1 2 3 $ x: int 1 2 3 向数据框添加列12345&gt; data$new &lt;- data$x * 2 g x new1 a 1 22 b 2 43 c 3 6 从数据框删除列12345&gt; data &lt;- subset(data,select = c(-x,-new)) g1 a2 b3 c 重排序列12345&gt; data2 &lt;-data[c(1,3,2)] g new x1 a 2 12 b 4 23 c 6 3 选取某几列12345&gt; data3 &lt;-data[c("x","new")] x new1 1 22 2 43 3 6 选取某几行1234&gt; data3 &lt;-data[c(1,2),] g x new1 a 1 22 b 2 unite 4 连续变量转换为分类变量12345&gt; data$class &lt;- cut(data$new,breaks=c(0,4,8,Inf)) g x new class1 a 1 2 (0,4]2 b 2 4 (0,4]3 c 3 6 (4,8] 宽数据《=》长数据长数据有一列数据是变量的类型，有一列是变量的值，但不一定只有两列。ggplot2需要长类型的数据，dplyr也需要长类型的数据，大多数的模型(比如lm(), glm()以及gam())也需要长数据。 使用tidyr 包的gather()函数转换到长数据： 123456789101112131415&gt; library(tidyr)&gt; data g x new1 a 1 22 b 2 43 c 3 6&gt; data2&lt;-gather(data,key='new_one',value ='count',x,new,-g)&gt; data2 g new_one count1 a x 12 b x 23 c x 34 a new 25 b new 46 c new 6 使用tidyr 包的spread()函数转换到宽数据： 12345&gt; spread(data2,key='new_one',value='count') g x new1 a 1 22 b 2 43 c 3 6 多列《=》一列123456789101112131415161718&gt; data g x new1 a 1 22 b 2 43 c 3 6&gt; data3&lt;-unite(data,x_new,x,new,sep = '_')&gt; data3 g x_new1 a 1_22 b 2_43 c 3_6&gt; data4&lt;- separate(data3,x_new,c('x','new'),sep = '_')&gt; data4 g x new1 a 1 22 b 2 43 c 3 6]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python Type Hint]]></title>
    <url>%2F2018%2F09%2F19%2Fpython-Type-Hint%2F</url>
    <content type="text"><![CDATA[引入​ 在C语言中每使用一个变量前要先将其声明，如 int a =1,float b =3.14。这么做的好处有2个，一是在之后代码中无需“猜测”变量到底是什么类型，声明是什么就是什么，这就是静态变量。二是少了“猜测”这一步，代码执行效率会有所提升。python默认所有的变量都是动态的，所以你无需提前声明类型，写出了一个变量a，赋值给他一个常数、列表、字典等等都可以。当然动态所带来的问题就是，在代码执行的时候需要去“猜测”变量的类型，从而降低了运行效率。 ​ 在python3.5及之后版本，python加入了模块typing，它允许在你命名变量的时候设定它的类型，抽象出来它长这个样子：variable : type，在设定一个变量类型为常量（int）之后并不会影响你给他赋值为字符串（str），这种类型设定如名字一样是类型暗示（Type Hint），而不是决定。 ​ 有一个名为mypy的包可以显式的帮你找出你在类型上的问题： 12pip install mypy$ mypy program.py 介绍可供使用的类型： Type Description int integer float floating point number bool boolean value str string (unicode) bytes 8-bit string object an arbitrary object (object is the common base class) List[str] list of str objects Tuple[int, int] tuple of two int objects (Tuple[()] is the empty tuple) Tuple[int, ...] tuple of an arbitrary number of int objects Dict[str, int] dictionary from str keys to int values Iterable[int] iterable object containing ints Sequence[bool] sequence of booleans (read-only) Mapping[str, int] mapping from str keys to int values (read-only) Any dynamically typed value with an arbitrary type Union[T1, ..., Tn] Union[int, str]both integers and strings are valid argument values. 方法12345678910111213141516171819202122from typing import List, Set, Dict, Tuple, Optional, Union, Anyx: int = 1x: float = 1.0x: bool = Truex: str = "test"x: bytes = b"test"x: List[int] = [1]x: Set[int] = &#123;6, 7&#125;x: Dict[str, float] = &#123;'field': 2.0&#125;x: Tuple[int, str, float] = (3, "yes", 7.5)x: List[Union[int, str]] = [3, 5, "test", "fun"] def plus(num1: int, num2: float) -&gt; float: return num1 + num2def f(x: Union[int, str]) -&gt; Any: if isinstance(x, int): # Here type of x is int. return (x + 1) # OK else: # Here type of x is str. return (x + 'a') # OK 123456def join(string_list): #定义一个方法，不做类型设定 return ', '.join(string_list)&gt;&gt;&gt; join('hello')'h, e, l, l, o'&gt;&gt;&gt; join(['hello','world'])'hello, world' 对于这个函数，期望的结果就是会把[‘hello’, ‘world’]变成’hello, world’。 但是如果不小心没有传list而是传了一个字符串’hello’，这段代码也不会报错，只是会返回’h, e, l, l, o’这个并不期望的结果。 1234567891011from typing import Listdef join(string_list: List[str]) -&gt; str: return ', '.join(string_list) #string_list 局部变量名， List[str] 局部变量类型， str 返回结果类型&gt;&gt;&gt; join('hello') #虽然不期待，但是仍可以运行'h, e, l, l, o'&gt;&gt;&gt; join(['hello','world'])'hello, world'&gt;&gt;&gt; join.__annotations__&#123;'string_list': typing.List[str], 'return': &lt;class 'str'&gt;&#125; 这样声明函数有一个好处，就是不需要在注释里面说明变量类型，更加直观。Python把这种类型的声明看成是一种对函数的注解(annotation)，而注解本身并不具有任何的意义，也不影响运行的过程。与没有注解的版本差别就是多了一个annotations的字段 。 123456from typing import Listdef join(string_list: List[str]) -&gt; str: return ', '.join(string_list)print(join('hello')) 运行以及使用mypy检查，代码可以运行，mypy也可以给出提示 1234$ python3 test_mypy.pyh, e, l, l, o$ mypy test_mypy.pytest_mypy.py:6: error: Argument 1 to "join" has incompatible type "str"; expected List[str]]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pandas和R中的groupby]]></title>
    <url>%2F2018%2F09%2F18%2Fgroupby-in-Python-and-R%2F</url>
    <content type="text"><![CDATA[groupby 可以根据一个数据框的部分数据，将整个数据框进行分组，简称：聚合。聚合之后，可以按组进行对数据进行统计分析。 pandas12345678910111213In [10]: df = pd.DataFrame(&#123;'key1' : ['a', 'a', 'b', 'b', 'a'], ....: 'key2' : ['one', 'two', 'one', 'two', 'one'], ....: 'data1' : np.random.randn(5), ....: 'data2' : np.random.randn(5)&#125;)In [11]: df #建立一个Dataframe数据框Out[11]: data1 data2 key1 key20 -0.204708 1.393406 a one1 0.478943 0.092908 a two2 -0.519439 0.281746 b one3 -0.555730 0.769023 b two4 1.965781 1.246435 a one 1234In [12]: grouped = df.groupby('key1') #按key1进行分组In [13]: grouped #得到的grouped一个简单处理的可迭代对象（GroupBy），实际上还没有进行任何计算Out[13]: &lt;pandas.core.groupby.DataframeGroupBy object at 0x0000000000FF07EB8&gt; 123456In [14]: grouped.mean() #调用GroupBy的mean方法来计算分组平均值：Out[14]: data1 data2key1a 0.114474 0.714913b 0.300820 -1.160967 12345678910In [15]: means = df.groupby(['key1', 'key2']).mean()['data1'] #按key1和key2分组，选出data1数据In [16]: meansOut[16]: key1 key2a one 0.880536 two 0.478943b one -0.519439 two -0.555730Name: data1, dtype: float64 1234567891011121314In [35]: people = pd.DataFrame(np.random.randn(5, 5), ....: columns=['a', 'b', 'c', 'd', 'e'], ....: index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])In [36]: people.iloc[2:3, [1, 2]] = np.nan # Add a few NA valuesIn [37]: people #另建一个数据框，拥有index名Out[37]: a b c d eJoe 1.007189 -1.296221 0.274992 0.228913 1.352917Steve 0.886429 -2.001637 -0.371843 1.669025 -0.438570Wes -0.539741 -2.001001 -2.001002 -1.021228 -0.577087Jim 0.124121 0.302614 0.523772 0.000940 1.343810Travis -0.713544 -0.831154 -2.370232 -1.860761 -0.860757 123456In [44]: people.groupby(len).sum() #用python函数分组将使用indexOut[44]: a b c d e3 0.591569 -0.993608 0.798764 -0.791374 2.1196395 0.886429 -2.001637 -0.371843 1.669025 -0.4385706 -0.713544 -0.831154 -2.370232 -1.860761 -0.860757 聚合运算方法 12345678In [54]: def peak_to_peak(arr): ....: return arr.max() - arr.min()In [55]: grouped.agg(peak_to_peak) #使用自己的聚合函数，将其传入aggregate或agg方法Out[55]: data1 data2key1 a 2.170488 1.300498b 0.036292 0.487276 1234567In [69]: grouped.agg(['mean','size']) #使用多个统计方法 In [69]: ftuples = [('fuc1', 'mean'),('fuc2', np.var)] #使用自定义的名字In [70]: grouped.agg(ftuples)In [71]: grouped.agg(&#123;'data1' : ['min', 'max', 'mean', 'std'], #不同列可以指定不同的统计方法 ....: 'data2' : ['sum']&#125;) R123456789101112131415161718192021222324252627library(dplyr) #group_by和summarise都在dplyr包中data &lt;- data.frame(year = rep(2016:2017,6),month = seq(1:12),sales=rep(c(10,20,30,40),3)) year month sales1 2016 1 102 2017 2 203 2016 3 304 2017 4 405 2016 5 106 2017 6 207 2016 7 308 2017 8 409 2016 9 1010 2017 10 2011 2016 11 3012 2017 12 40planes &lt;- group_by(data, year) #按年分组delay &lt;- summarise(planes, count = n(), #个数 max_mon = max(month), #最大值 min_mon = min(month), #最小值 avg_sales = mean(sales), #平均值 sum_sales = sum(sales)) #求和# A tibble: 2 x 6 year count max_mon min_mon avg_sales sum_sales &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;1 2016 6 11 1 20 1202 2017 6 12 2 30 180 常用的摘要函数123mean() sd() min() max() first() last() n() sum()median() #中位数quantile() #分位数，quantile(x，0.25)将会找出x从小到大排列，在25%时的数 聚合函数和逻辑筛选结合12345678910delay &lt;- summarise(planes, avg_sales_1 = mean(sales,na.rm=TRUE), #na.rm=TRUE,遇到NA值时不处理，因为统计时R默认NA值会传播，python不会 avg_sales_2 = mean(sales[sales&gt;10],na.rm=TRUE) #加入逻辑判断planes &lt;- group_by(data, year) #按年分组# A tibble: 2 x 3 year avg_sales_1 avg_sales_2 &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;1 2016 20. 30.2 2017 30. 30. 123456In [53]: grouped = df[df.data1&gt;0].groupby('key1') #逻辑筛选后按key1进行分组Out [53]: data1 data2key1a 0.679126 1.013678b 0.300820 -1.160967]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python标准库学习（二）]]></title>
    <url>%2F2018%2F09%2F18%2Fpython-standard-library-2%2F</url>
    <content type="text"><![CDATA[可迭代对象与迭代器可迭代对象与迭代器概念不同。可迭代对象在内部实现了__iter__，所以可以进行迭代，迭代器在内部实现了__iter__和__next__,所以是个迭代器也可以进行迭代。 举例： 1234&gt;&gt;&gt; mylist = [x for x in range(10)] #mylist是个列表，可以进行迭代&gt;&gt;&gt; mylist = （x for x in range(10)） #生成器表达式，结果同iter(mylist) #现在mylist是个迭代器，可以使用.next()方法 生成器生成器本质就是一个迭代器，自带了iter方法和next方法。迭代器是用来迭代可迭代对象的，而生成器是用来迭代方法的。调用函数的之后函数不执行，返回一个生成器每次调用next方法的时候会取到一个值直到取完最后一个，再执行next会报错。 生成器表达式类似于列表推导，但是，生成器返回按需产生结果的一个对象，而不是一次构建一个结果列表。 比较： 列表表达式在生成后可以按序列取值，排序，切片等，但是占用内存大。 生成器表达式只是产生一个可迭代对象，需要时再迭代取值，占用内存小，但是不可进行列表的操作，迭代完后对象清空。 itertoolsitertools.product产生多个列表和迭代器的笛卡尔积，可以用product来改写深度嵌套的列表推导操作。 1234&gt;&gt;&gt; x = itertools.product('ABC', range(3))&gt;&gt;&gt;&gt;&gt;&gt; print(list(x))[('A', 0), ('A', 1), ('A', 2), ('B', 0), ('B', 1), ('B', 2), ('C', 0), ('C', 1), ('C', 2)] itertools.accumulate简单来说就是累加。 1234&gt;&gt;&gt; import itertools&gt;&gt;&gt; x = itertools.accumulate(range(10))&gt;&gt;&gt; print(list(x))[0, 1, 3, 6, 10, 15, 21, 28, 36, 45] itertools.chain连接多个列表或者迭代器。 123&gt;&gt;&gt; x = itertools.chain(range(3), range(4), [3,2,1])&gt;&gt;&gt; print(list(x))[0, 1, 2, 0, 1, 2, 3, 3, 2, 1] itertools.combinations求列表或生成器中指定数目的元素不重复的所有组合 123&gt;&gt;&gt; x = itertools.combinations(range(4), 3)&gt;&gt;&gt; print(list(x))[(0, 1, 2), (0, 1, 3), (0, 2, 3), (1, 2, 3)] itertools.combinations_with_replacement允许重复元素的组合 123&gt;&gt;&gt; x = itertools.combinations_with_replacement('ABC', 2)&gt;&gt;&gt; print(list(x))[('A', 'A'), ('A', 'B'), ('A', 'C'), ('B', 'B'), ('B', 'C'), ('C', 'C')] itertools.count就是一个计数器,可以指定起始位置和步长 123&gt;&gt;&gt; x = itertools.count(start=20, step=-1)&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))[20, 19, 18, 17, 16, 15, 14, 13, 12, 11] itertools.cycle循环指定的列表和迭代器 123&gt;&gt;&gt; x = itertools.cycle('ABC')&gt;&gt;&gt; print(list(itertools.islice(x, 0, 10, 1)))['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C', 'A'] itertools.dropwhile按照真值函数丢弃掉列表和迭代器前面的元素 123&gt;&gt;&gt; x = itertools.dropwhile(lambda e: e &lt; 5, range(10))&gt;&gt;&gt; print(list(x))[5, 6, 7, 8, 9] itertools.takewhile与dropwhile相反，保留元素直至真值函数值为假。 123&gt;&gt;&gt; x = itertools.takewhile(lambda e: e &lt; 5, range(10))&gt;&gt;&gt; print(list(x))[0, 1, 2, 3, 4] itertools.filterfalse保留对应真值为False的元素 123&gt;&gt;&gt; x = itertools.filterfalse(lambda e: e &lt; 5, (1, 5, 3, 6, 9, 4))&gt;&gt;&gt; print(list(x))[5, 6, 9] itertools.groupby按照分组函数的值对元素进行分组 123456&gt;&gt;&gt; x = itertools.groupby(range(10), lambda x: x &lt; 5 or x &gt; 8) &gt;&gt;&gt; for condition, numbers in x: ... print(condition, list(numbers)) True [0, 1, 2, 3, 4] False [5, 6, 7, 8] True [9] itertools.islice上文使用过的函数，对迭代器进行切片 123&gt;&gt;&gt; x = itertools.islice(range(10), 0, 9, 2)&gt;&gt;&gt; print(list(x))[0, 2, 4, 6, 8] itertools.repeat简单的生成一个拥有指定数目元素的迭代器 123&gt;&gt;&gt; x = itertools.repeat(0, 5)&gt;&gt;&gt; print(list(x))[0, 0, 0, 0, 0] itertools.zip_longest类似于zip，不过已较长的列表和迭代器的长度为准 123456&gt;&gt;&gt; x = itertools.zip_longest(range(3), range(5))&gt;&gt;&gt; y = zip(range(3), range(5))&gt;&gt;&gt; print(list(x))[(0, 0), (1, 1), (2, 2), (None, 3), (None, 4)]&gt;&gt;&gt; print(list(y))[(0, 0), (1, 1), (2, 2)]]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[seqkit 使用说明]]></title>
    <url>%2F2018%2F09%2F13%2Fseqkit-usage%2F</url>
    <content type="text"><![CDATA[seqkit 是 Wei Shen 使用 go 语言编写处理 fa 和 fq 文件的一把利器，当前介绍版本为0.8.0。这里不详细介绍各个函数的参数，官方给出的文档已经足够。 软件地址：https://github.com/shenwei356/seqkit 12345678910111213141516171819202122232425262728Available Commands: common find common sequences of multiple files by id/name/sequence concat concatenate sequences with same ID from multiple files convert convert FASTQ quality encoding between Sanger, Solexa and Illumina duplicate duplicate sequences N times faidx create FASTA index file and extract subsequence fq2fa convert FASTQ to FASTA fx2tab convert FASTA/Q to tabular format (with length/GC content/GC skew) genautocomplete generate shell autocompletion script grep search sequences by pattern(s) of name or sequence motifs head print first N FASTA/Q records help Help about any command locate locate subsequences/motifs range print FASTA/Q records in a range (start:end) rename rename duplicated IDs replace replace name/sequence by regular expression restart reset start position for circular genome rmdup remove duplicated sequences by id/name/sequence sample sample sequences by number or proportion seq transform sequences (revserse, complement, extract ID...) shuffle shuffle sequences sliding sliding sequences, circular genome supported sort sort sequences by id/name/sequence/length split split sequences into files by id/seq region/size/parts stats simple statistics of FASTA/Q files subseq get subsequences by region/gtf/bed, including flanking sequences tab2fx convert tabular format to FASTA/Q format version print version information and check for update seq12345678910$ seqkit seq hairpin.fa.gz #展示fa文件&gt;cel-let-7 MI0000001 Caenorhabditis elegans let-7 stem-loopUACACUGUGGAUCCGGUGAGGUAGUAGGUUGUAUAGUUUGGAAUAUUACCACCGGUGAACUAUGCAAUUUUCUACCUUACCGGAGACAGAACUCUUCGA$ seqkit seq read_1.fq.gz #展示fq文件@HWI-D00523:240:HF3WGBCXX:1:1101:2574:2226 1:N:0:CTGTAGTGAGGAATATTGGTCAATGGGCGCGAGCCTGAACCAGCCAAGTAGCGTGAAGGATGACTGCCCTACGGG+HIHIIIIIHIIHGHHIHHIIIIIIIIIIIIIIIHHIIIIIHHIHIIIIIGIHIIIIHHHHHHGHIHIII 12345678910111213141516171819202122$ seqkit seq hairpin.fa.gz -n #展示序列全名cel-let-7 MI0000001 Caenorhabditis elegans let-7 stem-loopcel-lin-4 MI0000002 Caenorhabditis elegans lin-4 stem-loopcel-mir-1 MI0000003 Caenorhabditis elegans miR-1 stem-loop$ seqkit seq hairpin.fa.gz -n -i #展示序列IDcel-let-7cel-lin-4cel-mir-1$ seqkit seq hairpin.fa.gz -n -i --id-regexp "^[^\s]+\s([^\s]+)\s" #使用正则匹配序列名MI0000001MI0000002MI0000003$ seqkit seq hairpin.fa.gz -s -w 0 #只展示序列 并设置每行碱基数为默认UACACUGUGGAUCCGGUGAGGUAGUAGGUUGUAUAGUUUGGAAUAUUACCACCGGUGAACUAUGCAAUUUUCUACCUUACCGGAGACAGAACUCUUCGAAUGCUUCCGGCCUGUUCCCUGAGACCUCAAGUGUGAGUGUACUAUUGAUGCUUCACACCUGGGCUCUCCGGGUACCAGGACGGUUUGAGCAGAUAAAGUGACCGUACCGAGCUGCAUACUUCCUUACAUGCCCAUACUAUAUCAUAAAUGGAUAUGGAAUGUAAAGAAGUAUGUAGAACGGGGUGGUAGU 123456789101112$ seqkit seq hairpin.fa.gz -r -p #反转录序列&gt;cel-let-7 MI0000001 Caenorhabditis elegans let-7 stem-loopUCGAAGAGUUCUGUCUCCGGUAAGGUAGAAAAUUGCAUAGUUCACCGGUGGUAAUAUUCCAAACUAUACAACCUACUACCUCACCGGAUCCACAGUGUA$ echo -e "&gt;seq\nACGT-actgc-ACC" | seqkit seq -g -u #去除序列gap 并大写碱基&gt;seqACGTACTGCACC$ echo -e "&gt;seq\nUCAUAUGCUUGUCUCAAAGAUUA" | seqkit seq --rna2dna #DNA转RNA,--dna2rna亦可&gt;seqTCATATGCTTGTCTCAAAGATTA subseq1234567891011121314151617181920212223242526272829$ zcat hairpin.fa.gz | seqkit subseq -r 1:12 #展示序列前12个碱基$ zcat hairpin.fa.gz | seqkit subseq -r -12:-1 #后12个$ cat t.fa&gt;seqactgACTGactgn$ cat t.gtf #注意gtf文件格式，必须以\t分割。seq test CDS 5 8 . . . gene_id "A"; transcript_id "";seq test CDS 5 8 . - . gene_id "B"; transcript_id "";$ seqkit subseq --gtf t.gtf t.fa #使用gtf位置信息，挑选fa序列&gt;seq_5:8:. AACTG&gt;seq_5:8:- BCAGT$ seqkit subseq --gtf Homo_sapiens.GRCh38.84.gtf.gz --chr 1 --feature cds hsa.fa &gt; chr1.gtf.cds.fa #指定染色体和特征$ seqkit subseq --gtf t.gtf t.fa -u 3 #另加3bp上游序列&gt;seq_5:8:._us:3 ActgACTG&gt;seq_5:8:-_us:3 BagtCAGT$ seqkit subseq --gtf t.gtf t.fa -u 3 -f #只取上游3bp序列&gt;seq_5:8:._usf:3 Actg&gt;seq_5:8:-_usf:3 Bagt gff3 文件第九列格式为ID=XXXXX; gtf 文件第九列格式为 gene_id “A”; transcript_id “”; stats123456$ seqkit stats *.f&#123;a,q&#125;.gz #统计序列信息file format type num_seqs sum_len min_len avg_len max_lenhairpin.fa.gz FASTA RNA 28,645 2,949,871 39 103 2,354mature.fa.gz FASTA RNA 35,828 781,222 15 21.8 34reads_1.fq.gz FASTQ DNA 2,500 567,516 226 227 229reads_2.fq.gz FASTQ DNA 2,500 560,002 223 224 225 faidx1234567$ seqkit faidx hairpin.fa #建立序列索引&gt;hsa-let-7a-1UGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA&gt;hsa-let-7a-2AGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGAUAACUGUACAGCCUCCUAGCUUUCCU fq2fa1$ seqkit fq2fa reads_1.fq.gz -o reads1_.fa.gz #fq转fa convert123456789101112131415161718192021$ seqkit head -n 1 tests/Illimina1.8.fq.gz...#AAAFAAJFFFJJJ&lt;JJJJJFFFJFJJJJJFJJAJJJFJJFJFJJJJFAFJ&lt;JA&lt;FFJ7FJJFJJAAJJJJ&lt;JJJJJJJFJJJAJJJJJFJJ77&lt;JJJJ-F7A-FJFFJJJJJJ&lt;FFJ-&lt;7FJJJFJJ)A7)7AA&lt;7--)&lt;-7F-A7FA&lt;$ seqkit convert tests/Illimina1.8.fq.gz | seqkit head -n 1 #默认转换fq文件质量值到1.8+[INFO] possible quality encodings: [Illumina-1.8+][INFO] guessed quality encoding: Illumina-1.8+[INFO] converting Illumina-1.8+ -&gt; Sanger[WARN] source and target quality encoding match....#AAAFAAJFFFJJJ&lt;JJJJJFFFJFJJJJJFJJAJJJFJJFJFJJJJFAFJ&lt;JA&lt;FFJ7FJJFJJAAJJJJ&lt;JJJJJJJFJJJAJJJJJFJJ77&lt;JJJJ-F7A-FJFFJJJJJJ&lt;FFJ-&lt;7FJJJFJJ)A7)7AA&lt;7--)&lt;-7F-A7FA&lt;$ seqkit convert tests/Illimina1.8.fq.gz --to Illumina-1.5+ | seqkit head -n 1[INFO] possible quality encodings: [Illumina-1.8+] [INFO] guessed quality encoding: Illumina-1.8+[INFO] converting Illumina-1.8+ -&gt; Illumina-1.5+ #转换 Illumina1.8+ -&gt; Illumina1.5+...B```e``ieeeiii[iiiiieeeieiiiiieii`iiieiieieiiiie`ei[i`[eeiVeiieii``iiii[iiiiiiieiii`iiiiieiiVV[iiiiLeV`Leieeiiiiii[eeiL[VeiiieiiH`VHV``[VLLH[LVeL`Ve`[ grep123456789101112131415$ zcat hairpin.fa.gz | seqkit grep -r -p ^hsa #正则匹配序列名&gt;hsa-let-7a-1 MI0000060 Homo sapiens let-7a-1 stem-loopUGGGAUGAGGUAGUAGGUUGUAUAGUUUUAGGGUCACACCCACCACUGGGAGAUAACUAUACAAUCUACUGUCUUUCCUA&gt;hsa-let-7a-2 MI0000061 Homo sapiens let-7a-2 stem-loopAGGUUGAGGUAGUAGGUUGUAUAGUUUAGAAUUACAUCAAGGGAGAUAACUGUACAGCCUCCUAGCUUUCCU$ zcat hairpin.fa.gz | seqkit grep -r -p ^hsa -p ^mmu -v #2个条件并取反$ zcat hairpin.fa.gz | seqkit grep -f list &gt; new.fa #将需要提取的序列名放在list中$ zcat hairpin.fa.gz | seqkit grep -s -r -i -p ^aggcg #正则匹配序列碱基，-i 忽略大小写$ seqkit grep -s -R 1:30 -i -r -p GCTGG #-R 在前30个碱基中正则匹配 rmdup12345678910$ zcat hairpin.fa.gz | seqkit rmdup -s -o clean.fa.gz #去除重复的序列[INFO] 2226 duplicated records removed$ zcat hairpin.fa.gz | seqkit rmdup -s -i -m -o clean.fa.gz -d duplicated.fa.gz -D duplicated.detail.txt #-d输出重复序列，-D统计重复序列$ cat duplicated.detail.txt # here is not the entire list3 hsa-mir-424, mml-mir-424, ppy-mir-4243 hsa-mir-342, mml-mir-342, ppy-mir-3422 ngi-mir-932, nlo-mir-9322 ssc-mir-9784-1, ssc-mir-9784-2 common123$ seqkit common file*.fa -o common.fasta #通过ID寻找共同序列$ seqkit common file*.fa -n -o common.fasta #通过全名$ seqkit common file*.fa -s -i -o common.fasta #通过序列 split1234567891011121314151617181920212223242526272829303132333435363738394041424344$ seqkit split hairpin.fa.gz -s 10000 #按序列数分割文件[INFO] split into 10000 seqs per file[INFO] write 10000 sequences to file: hairpin.fa.part_001.gz[INFO] write 10000 sequences to file: hairpin.fa.part_002.gz[INFO] write 8645 sequences to file: hairpin.fa.part_003.gz $ seqkit split hairpin.fa.gz -p 4 #按文件个数分割文件[INFO] split into 4 parts[INFO] read sequences ...[INFO] read 28645 sequences[INFO] write 7162 sequences to file: hairpin.fa.part_001.gz[INFO] write 7162 sequences to file: hairpin.fa.part_002.gz[INFO] write 7162 sequences to file: hairpin.fa.part_003.gz[INFO] write 7159 sequences to file: hairpin.fa.part_004.gz$ seqkit split hairpin.fa.gz -p 4 -2 #-2减少内存使用[INFO] split into 4 parts[INFO] read and write sequences to tempory file: hairpin.fa.gz.fa ...[INFO] create and read FASTA index ...[INFO] read sequence IDs from FASTA index ...[INFO] 28645 sequences loaded[INFO] write 7162 sequences to file: hairpin.part_001.fa.gz[INFO] write 7162 sequences to file: hairpin.part_002.fa.gz[INFO] write 7162 sequences to file: hairpin.part_003.fa.gz[INFO] write 7159 sequences to file: hairpin.part_004.fa.gz$ seqkit split hairpin.fa.gz -i --id-regexp "^([\w]+)\-" -2 #按ID[INFO] split by ID. idRegexp: ^([\w]+)\-[INFO] read and write sequences to tempory file: hairpin.fa.gz.fa ...[INFO] create and read FASTA index ...[INFO] create FASTA index for hairpin.fa.gz.fa[INFO] read sequence IDs from FASTA index ...[INFO] 28645 sequences loaded[INFO] write 48 sequences to file: hairpin.id_cca.fa.gz[INFO] write 3 sequences to file: hairpin.id_hci.fa.gz$ seqkit split hairpin.fa.gz -r 1:3 -2 #按前3个碱基[INFO] split by region: 1:3[INFO] read and write sequences to tempory file: hairpin.fa.gz.fa ...[INFO] read sequence IDs and sequence region from FASTA file ...[INFO] create and read FASTA index ...[INFO] write 463 sequences to file: hairpin.region_1:3_AUG.fa.gz[INFO] write 349 sequences to file: hairpin.region_1:3_ACU.fa.gz[INFO] write 311 sequences to file: hairpin.region_1:3_CGG.fa.gz range1$ cat hairpin.fa | seqkit range -r 101:150 #输出范围内的序列（1:12 如同 head -n 12） sort1234567891011121314151617181920$ echo -e "&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA" | seqkit sort --quiet #按ID排序，--quiet不输出提示信息&gt;SEQ2acgtnAAAA&gt;seq1ACGTNcccc$ echo -e "&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAA" | seqkit sort --quiet -i #不区分大小写&gt;seq1ACGTNcccc&gt;SEQ2acgtnAAAA$ echo -e "&gt;seq1\nACGTNcccc\n&gt;SEQ2\nacgtnAAAAnnn\n&gt;seq3\nacgt" | seqkit sort --quiet -l #按序列长度&gt;seq3acgt&gt;seq1ACGTNcccc&gt;SEQ2acgtnAAAAnnn 0.9.0版本中加入 -r 参数，可以反转排序结果。]]></content>
      <categories>
        <category>biotool</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python标准库学习（一）]]></title>
    <url>%2F2018%2F09%2F11%2Fpython-standard-library-1%2F</url>
    <content type="text"><![CDATA[collections该模块实现专门的容器数据类型，提供Python通用内置容器（dict，set，list，tuple）的替代方案。 nametuple() 工厂函数用于创建带有命名字段的元组子类 deque() 列表式容器，在两端有快速附加和弹出 ChainMap() 类似于类的类，用于创建多个映射的单个视图 Counter () dict子类用于计算hashable对象 OrderedDict () dict子类，记住已添加的条目的顺序 defaultdict () dict子类调用一个工厂函数时提供缺失值 UserDict () 包装字典对象，更容易dict子类化 UserList () 包装列表对象以方便列表子类化 UserString() 包装字符串对象，更容易字符串子类化 ChainMapChainMap用来将多个dict(字典)组成一个list(只是比喻)，可以理解成合并多个字典，但和update不同，而且效率更高。 ChainMap用来将多个dict组成一个list之后，多个dict之间的键不冲突。当多个dict有重复键时，使用get方法：如chainMap.get(&#39;name&#39;)将会返回第一个dict[‘name’]。 123456789101112131415161718192021222324252627282930313233343536# 新建ChainMap及它的结构In[2]: from collections import ChainMapIn[3]: m1 = &#123;'color': 'red', 'user': 'guest'&#125;In[4]: m2 = &#123;'name': 'drfish', 'age': '18'&#125;In[5]: chainMap = ChainMap(m1, m2)In[6]: print(chainMap.items())ItemsView(ChainMap(&#123;'color': 'red', 'user': 'guest'&#125;, &#123;'name': 'drfish', 'age': '18'&#125;))# 获取ChainMap中的元素In[7]: print(chainMap.get('name'))drfishIn[8]: print(chainMap.get('not'))None# 新增mapIn[9]: m3 = &#123;'name': 'boy'&#125;In[10]: chainMap = chainMap.new_child(m3)In[11]: print(chainMap.items())ItemsView(ChainMap(&#123;'name': 'boy'&#125;, &#123;'color': 'red', 'user': 'guest'&#125;, &#123;'name': 'drfish', 'age': '18'&#125;))In[12]: print(chainMap.get('name'))'boy'#一次遍历多个字典In[13]: for i in chainMap.maps: print("----------------") for mykey in i.keys(): print(mykey,i[mykey]) ----------------name boy----------------color reduser guest----------------name drfishage 18 CounterCounter是一个简单的计数器，使用起来非常方便。 123456789101112131415161718192021&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; c = Counter(a=4, b=2, c=0, d=-2) #不大于0的全部忽略&gt;&gt;&gt; sorted(c.elements())['a', 'a', 'a', 'a', 'b', 'b']&gt;&gt;&gt; Counter('abracadabra').most_common(3) #返回出现次数最多的字符[('a', 5), ('r', 2), ('b', 2)]&gt;&gt;&gt; cnt = Counter() # 统计列表中元素出现的个数&gt;&gt;&gt; for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:... cnt[word] += 1...&gt;&gt;&gt; cntCounter(&#123;'blue': 3, 'red': 2, 'green': 1&#125;) &gt;&gt;&gt; cnt = Counter() # 统计字符串中元素出现的个数&gt;&gt;&gt; for ch in 'hello':... cnt[ch] = cnt[ch] + 1...&gt;&gt;&gt; cntCounter(&#123;'l': 2, 'o': 1, 'h': 1, 'e': 1&#125;) dequedeque就是一个双端队列，与list非常相似，不过可以同时在list的左边增删元素，支持线程安全 ，从队列两端添加或弹出元素的复杂度都是O(1)，而从列表的头部插入或移除元素时，列表的复杂度为O(N)。 deque和list从中部处理数据复杂度都为为O(N)。 123456789101112In[72]: dq = deque('abc')In[73]: dqOut[73]: deque(['a', 'b', 'c'])In[74]: dq.append('A')In[75]: dq.appendleft('Z')In[76]: dqOut[76]: deque(['Z', 'a', 'b', 'd', 'A'])In[77]: dq.popleft()Out[77]: 'Z'In[78]: dq.extendleft("hello")In[79]: dqOut[79]: deque(['o', 'l', 'l', 'e', 'h', 'a', 'b', 'c', 'A']) defaultdict使用 list 作为 default_factory，很容易将键值对的序列分组到列表的字典,类似setdefault 当第一次遇到每个键时，它不在映射中；因此使用返回空 list 的 default_factory 函数自动创建一个条目。然后，list.append() 操作将值附加到新列表。当再次遇到键时，查找继续正常（返回该键的列表），list.append() 操作将另一个值添加到列表。这种技术比使用 dict.setdefault() 的等效技术更简单和更快 12345678&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]&gt;&gt;&gt; d = defaultdict(list)&gt;&gt;&gt; for k, v in s:... d[k].append(v)...&gt;&gt;&gt; sorted(d.items())[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])] 1234567&gt;&gt;&gt; d = &#123;&#125;&gt;&gt;&gt; s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]&gt;&gt;&gt; for k, v in s:... d.setdefault(k,[]).append(v)...&gt;&gt;&gt; sorted(d.items())[('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])] 将 default_factory 设置为int 使 defaultdict 可用于计数,当首次遇到字母时，映射中缺少字母，因此 default_factory 函数调用 int() 以提供默认计数为零。增量操作然后建立每个字母的计数。 1234567&gt;&gt;&gt; s = 'mississippi'&gt;&gt;&gt; d = defaultdict(int)&gt;&gt;&gt; for k in s:... d[k] += 1...&gt;&gt;&gt; sorted(d.items())[('i', 4), ('m', 1), ('p', 2), ('s', 4)] 将 default_factory 设置为 set使得 defaultdict 可用于构建集合的字典 1234567&gt;&gt;&gt; s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)]&gt;&gt;&gt; d = defaultdict(set)&gt;&gt;&gt; for k, v in s:... d[k].add(v)...&gt;&gt;&gt; sorted(d.items())[('blue', &#123;2, 4&#125;), ('red', &#123;1, 3&#125;)] OrderedDict有序字典与常规字典类似，但它们记住项目插入的顺序。在对有序字典进行迭代时，项目按它们的键首次添加的顺序返回。]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python-underscore]]></title>
    <url>%2F2018%2F09%2F10%2Fpython-underscore%2F</url>
    <content type="text"><![CDATA[_name以单下划线开头，表示这是一个保护成员，只有类对象和子类对象自己能访问到这些变量。以单下划线开头的变量和函数被默认当作是内部函数，使用from module improt *时不会被获取，但是使用import module可以获取 name_以单下划线结尾仅仅是为了区别该名称与关键词 __name双下划线开头，表示为私有成员，只允许类本身访问，子类也不行。在文本上被替换为_class__method name双下划线开头，双下划线结尾。一种约定，Python内部的名字，用来区别其他用户自定义的命名,以防冲突。是一些 Python 的“魔术”对象，表示这是一个特殊成员，例如：定义类的时候，若是添加init方法，那么在创建类的实例的时候，实例会自动调用这个方法，一般用来对实例的属性进行初使化，Python不建议将自己命名的方法写为这种形式]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ruby部分代码风格]]></title>
    <url>%2F2018%2F09%2F10%2Fruby-guide-tips%2F</url>
    <content type="text"><![CDATA[每个缩排层级使用两个空格。不要使用制表符. 123456789# 差 - 四个空格def some_method do_somethingend# 好def some_method do_somethingend 范围的字面量语法中，不要添加任何空格。 1234567# 差1 .. 3'a' ... 'z'# 好1..3'a'...'z' 使用 _ 语法改善大数的数值字面量的可读性。 12345# 差 - 有几个零？num = 1000000# 好 - 方便人脑理解num = 1_000_000 使用 def 定义方法时，如果有参数则使用括号，如果无参数则省略括号。 12345678910111213141516171819# 差def some_method() # 省略主体end# 好def some_method # 省略主体end# 差def some_method_with_parameters param1, param2 # 省略主体end# 好def some_method_with_parameters(param1, param2) # 省略主体end 除非必要，否则避免在并行赋值时使用单字符的 _ 变量。优先考虑前缀形式的下划线变量，而不是直接使用 _，因为前者可以提供一定的语义信息。但当赋值语句左侧出现带 * 操作符的变量时，使用 _ 也是可以接受的。 123456789101112131415foo = 'one,two,three,four,five'# 差 _可有可无，且无任何有用信息first, second, _ = foo.split(',')first, _, _ = foo.split(',')first, *_ = foo.split(',')# 好 _可有可无，但提供了额外信息first, _second = foo.split(',')first, _second, = foo.split(',')first, *_ending = foo.split(',')# 好 _占位符，_ 担当最后一个元素*beginning, _ = foo.split(',')*beginning, something, _ = foo.split(',') 永远不要使用 for， 除非你很清楚为什么。大部分情况下，你应该使用迭代器。for 是由 each 实现的，所以你绕弯了。另外，for 没有引入一个新的作用域 (each 有），因此在它内部定义的变量在外部仍是可见的。 123456789101112131415arr = [1, 2, 3]# 差for elem in arr do puts elemend# 注意，elem 可在 for 循环外部被访问elem # =&gt; 3# 好arr.each &#123; |elem| puts elem &#125;# 注意，elem 不可在 each 块外部被访问elem # =&gt; NameError: undefined local variable or method `elem' 倾向使用三元操作符（?:）而不是 if/then/else/end 结构。前者更为常见且简练。 12345# 差result = if some_condition then something else something_else end# 好result = some_condition ? something : something_else 永远不要使用 if x; ...。使用三元操作符来替代。 12345# 差result = if some_condition; something else something_else end# 好result = some_condition ? something : something_else 使用 ! 而不是 not。 12345# 差 - 因为操作符的优先级，这里必须使用括号x = (not something)# 好x = !something 永远不要使用 and 与 or 关键字。使用 &amp;&amp; 与 || 来替代。 12345678910111213141516# 差# 布尔表达式ok = got_needed_arguments and arguments_are_valid# 流程控制document.save or fail(RuntimeError, "Failed to save document!")# 好# 布尔表达式ok = got_needed_arguments &amp;&amp; arguments_are_valid# 流程控制fail(RuntimeError, "Failed to save document!") unless document.save# 流程控制document.save || fail(RuntimeError, "Failed to save document!") 对于单行主体，倾向使用 {...} 而不是 do...end。对于多行主体，避免使用 {...}。对于“流程控制”或“方法定义”（比如 Rakefile、其他 DSL 构成片段），总是使用 do...end。避免在链式方法调用中使用 do...end. 1234567891011121314151617names = %w[Bozhidar Steve Sarah]# 差names.each do |name| puts nameend# 好names.each &#123; |name| puts name &#125;# 差names.select do |name| name.start_with?('S')end.map &#123; |name| name.upcase &#125;# 好names.select &#123; |name| name.start_with?('S') &#125;.map(&amp;:upcase) 某些人可能会争论在多行链式方法调用时使用 {...} 看起来还可以。但他们应该扪心自问——这样的代码真的可读吗？难道不能把区块内容提取出来放到小巧的方法里吗？ #我觉得写成代码块易读。 避免在不需要流程控制的情况下使用 return。 123456789# 差def some_method(some_arr) return some_arr.sizeend# 好def some_method(some_arr) some_arr.sizeend 嗯。。。很魔幻。 通过使用范围或 Comparable#between? 来替代复杂的比较逻辑。 12345678# 差do_something if x &gt;= 1000 &amp;&amp; x &lt;= 2000# 好do_something if (1000..2000).include?(x)# 好do_something if x.between?(1000, 2000) 当创建一组元素为单词（没有空格或特殊字符）的数组时，倾向使用 %w 而不是 []。此规则只适用于数组元素有两个或以上的时候。 12345# 差STATES = ['draft', 'open', 'closed']# 好STATES = %w[draft open closed] 倾向使用符号而不是字符串作为哈希键。 12345# 差hash = &#123; 'one' =&gt; 1, 'two' =&gt; 2, 'three' =&gt; 3 &#125;# 好hash = &#123; 'one': 1, 'two': 2, 'three': 3 &#125; 倾向使用 Hash#each_key 而不是 Hash#keys.each，使用 Hash#each_value 而不是 Hash#values.each。 123456789# 差hash.keys.each &#123; |k| p k &#125;hash.values.each &#123; |v| p v &#125;hash.each &#123; |k, _v| p k &#125;hash.each &#123; |_k, v| p v &#125;# 好hash.each_key &#123; |k| p k &#125;hash.each_value &#123; |v| p v &#125;]]></content>
      <categories>
        <category>ruby</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pandas学习（二）]]></title>
    <url>%2F2018%2F09%2F06%2Fpandas-2%2F</url>
    <content type="text"><![CDATA[算术运算和数据对齐pandas最重要的一个功能是，它可以对不同索引的对象进行算术运算。在将对象相加时，如果存在不同的索引对，则结果的索引就是该索引对的并集。对于有数据库经验的用户，这就像在索引标签上进行自动外连接。看一个简单的例子： 123456789101112131415161718192021In [150]: s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])In [151]: s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], .....: index=['a', 'c', 'e', 'f', 'g'])In [152]: s1Out[152]: a 7.3c -2.5d 3.4e 1.5dtype: float64In [153]: s2Out[153]: a -2.1c 3.6e -1.5f 4.0g 3.1dtype: float64 将它们相加就会产生： 123456789In [154]: s1 + s2Out[154]: a 5.2c 1.1d NaNe 0.0f NaNg NaNdtype: float64 自动的数据对齐操作在不重叠的索引处引入了NA值。缺失值会在算术运算过程中传播。 对于DataFrame，对齐操作会同时发生在行和列上： 1234567891011121314151617181920In [155]: df1 = pd.DataFrame(np.arange(9.).reshape((3, 3)), columns=list('bcd'), .....: index=['Ohio', 'Texas', 'Colorado'])In [156]: df2 = pd.DataFrame(np.arange(12.).reshape((4, 3)), columns=list('bde'), .....: index=['Utah', 'Ohio', 'Texas', 'Oregon'])In [157]: df1Out[157]: b c dOhio 0.0 1.0 2.0Texas 3.0 4.0 5.0Colorado 6.0 7.0 8.0In [158]: df2Out[158]: b d eUtah 0.0 1.0 2.0Ohio 3.0 4.0 5.0Texas 6.0 7.0 8.0Oregon 9.0 10.0 11.0 把它们相加后将会返回一个新的DataFrame，其索引和列为原来那两个DataFrame的并集： 12345678In [159]: df1 + df2Out[159]: b c d eColorado NaN NaN NaN NaNOhio 3.0 NaN 6.0 NaNOregon NaN NaN NaN NaNTexas 9.0 NaN 12.0 NaNUtah NaN NaN NaN NaN 因为’c’和’e’列均不在两个DataFrame对象中，在结果中以缺省值呈现。行也是同样。 在算术方法中填充值在对不同索引的对象进行算术运算时，你可能希望当一个对象中某个轴标签在另一个对象中找不到时填充一个特殊值（比如0）： 12345678910111213141516171819202122In [165]: df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), .....: columns=list('abcd'))In [166]: df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), .....: columns=list('abcde'))In [167]: df2.loc[1, 'b'] = np.nanIn [168]: df1Out[168]: a b c d0 0.0 1.0 2.0 3.01 4.0 5.0 6.0 7.02 8.0 9.0 10.0 11.0In [169]: df2Out[169]: a b c d e0 0.0 1.0 2.0 3.0 4.01 5.0 NaN 7.0 8.0 9.02 10.0 11.0 12.0 13.0 14.03 15.0 16.0 17.0 18.0 19.0 将它们相加时，没有重叠的位置就会产生NA值： 1234567In [170]: df1 + df2Out[170]: a b c d e0 0.0 2.0 4.0 6.0 NaN1 9.0 NaN 13.0 15.0 NaN2 18.0 20.0 22.0 24.0 NaN3 NaN NaN NaN NaN NaN 使用df1的add方法，传入df2以及一个fill_value参数： 1234567In [171]: df1.add(df2, fill_value=0)Out[171]: a b c d e0 0.0 2.0 4.0 6.0 4.01 9.0 5.0 13.0 15.0 9.02 18.0 20.0 22.0 24.0 14.03 15.0 16.0 17.0 18.0 19.0 与此类似，在对Series或DataFrame重新索引时，也可以指定一个填充值： 123456In [174]: df1.reindex(columns=df2.columns, fill_value=0)Out[174]: a b c d e0 0.0 1.0 2.0 3.0 01 4.0 5.0 6.0 7.0 02 8.0 9.0 10.0 11.0 0 DataFrame和Series之间的运算跟不同维度的NumPy数组一样，DataFrame和Series之间算术运算也是有明确规定的。先来看一个具有启发性的例子，计算一个二维数组与其某行之间的差： 12345678910111213141516In [175]: arr = np.arange(12.).reshape((3, 4))In [176]: arrOut[176]: array([[ 0., 1., 2., 3.], [ 4., 5., 6., 7.], [ 8., 9., 10., 11.]])In [177]: arr[0]Out[177]: array([ 0., 1., 2., 3.])In [178]: arr - arr[0]Out[178]: array([[ 0., 0., 0., 0.], [ 4., 4., 4., 4.], [ 8., 8., 8., 8.]]) 当我们从arr减去arr[0]，每一行都会执行这个操作。这就叫做广播（broadcasting），附录A将对此进行详细讲解。DataFrame和Series之间的运算差不多也是如此： 1234567891011121314151617181920In [179]: frame = pd.DataFrame(np.arange(12.).reshape((4, 3)), .....: columns=list('bde'), .....: index=['Utah', 'Ohio', 'Texas', 'Oregon'])In [180]: series = frame.iloc[0]In [181]: frameOut[181]: b d eUtah 0.0 1.0 2.0Ohio 3.0 4.0 5.0Texas 6.0 7.0 8.0Oregon 9.0 10.0 11.0In [182]: seriesOut[182]: b 0.0d 1.0e 2.0Name: Utah, dtype: float64 默认情况下，DataFrame和Series之间的算术运算会将Series的索引匹配到DataFrame的列，然后沿着行一直向下广播： 1234567In [183]: frame - seriesOut[183]: b d eUtah 0.0 0.0 0.0Ohio 3.0 3.0 3.0Texas 6.0 6.0 6.0Oregon 9.0 9.0 9.0 如果某个索引值在DataFrame的列或Series的索引中找不到，则参与运算的两个对象就会被重新索引以形成并集： 123456789In [184]: series2 = pd.Series(range(3), index=['b', 'e', 'f'])In [185]: frame + series2Out[185]: b d e fUtah 0.0 NaN 3.0 NaNOhio 3.0 NaN 6.0 NaNTexas 6.0 NaN 9.0 NaNOregon 9.0 NaN 12.0 NaN 如果你希望匹配行且在列上广播，则必须使用算术运算方法。例如： 12345678910111213141516171819202122232425In [186]: series3 = frame['d']In [187]: frameOut[187]: b d eUtah 0.0 1.0 2.0Ohio 3.0 4.0 5.0Texas 6.0 7.0 8.0Oregon 9.0 10.0 11.0In [188]: series3Out[188]: Utah 1.0Ohio 4.0Texas 7.0Oregon 10.0Name: d, dtype: float64In [189]: frame.sub(series3, axis='index')Out[189]: b d eUtah -1.0 0.0 1.0Ohio -1.0 0.0 1.0Texas -1.0 0.0 1.0Oregon -1.0 0.0 1.0 传入的轴号就是希望匹配的轴。在本例中，我们的目的是匹配DataFrame的行索引（axis=’index’ or axis=0）并进行广播。 函数应用和映射NumPy的ufuncs（元素级数组方法）也可用于操作pandas对象： 123456789101112131415161718In [190]: frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'), .....: index=['Utah', 'Ohio', 'Texas', 'Oregon'])In [191]: frameOut[191]: b d eUtah -0.204708 0.478943 -0.519439Ohio -0.555730 1.965781 1.393406Texas 0.092908 0.281746 0.769023Oregon 1.246435 1.007189 -1.296221In [192]: np.abs(frame)Out[192]: b d eUtah 0.204708 0.478943 0.519439Ohio 0.555730 1.965781 1.393406Texas 0.092908 0.281746 0.769023Oregon 1.246435 1.007189 1.296221 另一个常见的操作是，将函数应用到由各列或行所形成的一维数组上。DataFrame的apply方法即可实现此功能： 12345678In [193]: f = lambda x: x.max() - x.min()In [194]: frame.apply(f)Out[194]: b 1.802165d 1.684034e 2.689627dtype: float64 这里的函数f，计算了一个Series的最大值和最小值的差，在frame的每列都执行了一次。结果是一个Series，使用frame的列作为索引。 如果传递axis=’columns’到apply，这个函数会在每行执行： 1234567In [195]: frame.apply(f, axis='columns')Out[195]:Utah 0.998382Ohio 2.521511Texas 0.676115Oregon 2.542656dtype: float64 许多最为常见的数组统计功能都被实现成DataFrame的方法（如sum和mean），因此无需使用apply方法。 传递到apply的函数不是必须返回一个标量，还可以返回由多个值组成的Series： 12345678In [196]: def f(x): .....: return pd.Series([x.min(), x.max()], index=['min', 'max'])In [197]: frame.apply(f)Out[197]: b d emin -0.555730 0.281746 -1.296221max 1.246435 1.965781 1.393406 汇总和计算描述统计pandas对象拥有一组常用的数学和统计方法。它们大部分都属于约简和汇总统计，用于从Series中提取单个值（如sum或mean）或从DataFrame的行或列中提取一个Series。跟对应的NumPy数组方法相比，它们都是基于没有缺失数据的假设而构建的。看一个简单的DataFrame： 123456789101112In [230]: df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], .....: [np.nan, np.nan], [0.75, -1.3]], .....: index=['a', 'b', 'c', 'd'], .....: columns=['one', 'two'])In [231]: dfOut[231]: one twoa 1.40 NaNb 7.10 -4.5c NaN NaNd 0.75 -1.3 调用DataFrame的sum方法将会返回一个含有列的和的Series： 12345In [232]: df.sum()Out[232]: one 9.25two -5.80dtype: float64 传入axis=’columns’或axis=1将会按行进行求和运算： 123456In [233]: df.sum(axis=1)Out[233]:a 1.40b 2.60c NaNd -0.55 NA值会自动被排除，除非整个切片（这里指的是行或列）都是NA。通过skipna选项可以禁用该功能： 1234567In [234]: df.mean(axis='columns', skipna=False)Out[234]: a NaNb 1.300c NaNd -0.275dtype: float64]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pandas学习（一）]]></title>
    <url>%2F2018%2F09%2F05%2Fpandas-1%2F</url>
    <content type="text"><![CDATA[导入 pandas、numpy、matplotlib 12345In [1]: import pandas as pdIn [2]: import numpy as npIn [3]: import matplotlib.pyplot as plt 创造对象Series 是一个值的序列，它只有一个列，以及索引。下面的例子中，就用默认的整数索引 1234567891011In [4]: s = pd.Series([1,3,5,np.nan,6,8])In [5]: sOut[5]: 0 11 32 53 NaN4 65 8dtype: float64 DataFrame 是有多个列的数据表，每个列拥有一个 label，当然，DataFrame 也有索引 1234567891011121314151617181920In [6]: dates = pd.date_range('20130101', periods=6)In [7]: datesOut[7]: DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D')In [8]: df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))#index 行名，columns，列名。都需要提供一个列表对象In [9]: dfOut[9]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-05 -0.424972 0.567020 0.276232 -1.0874012013-01-06 -0.673690 0.113648 -1.478427 0.524988 如果参数是一个 dict，每个 dict 的 value 会被转化成一个 Series 123456789101112131415In [10]: df2 = pd.DataFrame(&#123; 'A' : 1., ....: 'B' : pd.Timestamp('20130102'), ....: 'C' : pd.Series(1,index=list(range(4)),dtype='float32'), ....: 'D' : np.array([3] * 4,dtype='int32'), ....: 'E' : pd.Categorical(["test","train","test","train"]), ....: 'F' : 'foo' &#125;) ....: In [11]: df2Out[11]: A B C D E F0 1 2013-01-02 1 3 test foo1 1 2013-01-02 1 3 train foo2 1 2013-01-02 1 3 test foo3 1 2013-01-02 1 3 train foo 每列的格式用 dtypes 查看 123456789In [12]: df2.dtypesOut[12]: A float64B datetime64[ns]C float32D int32E categoryF objectdtype: object 你可以认为，DataFrame 是由 Series 组成的 1234567In [13]: df2.AOut[13]: 0 11 12 13 1Name: A, dtype: float64 查看数据用 head 和 tail 查看顶端和底端的几列 123456789101112131415In [14]: df.head()Out[14]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-05 -0.424972 0.567020 0.276232 -1.087401In [15]: df.tail(3)Out[15]: A B C D2013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-05 -0.424972 0.567020 0.276232 -1.0874012013-01-06 -0.673690 0.113648 -1.478427 0.524988 实际上，DataFrame 内部用 numpy 格式存储数据。你也可以单独查看 index 和 columns 1234567891011121314151617In [16]: df.indexOut[16]: DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04', '2013-01-05', '2013-01-06'], dtype='datetime64[ns]', freq='D')In [17]: df.columnsOut[17]: Index(['A', 'B', 'C', 'D'], dtype='object')In [18]: df.valuesOut[18]: array([[ 0.4691, -0.2829, -1.5091, -1.1356], [ 1.2121, -0.1732, 0.1192, -1.0442], [-0.8618, -2.1046, -0.4949, 1.0718], [ 0.7216, -0.7068, -1.0396, 0.2719], [-0.425 , 0.567 , 0.2762, -1.0874], [-0.6737, 0.1136, -1.4784, 0.525 ]]) describe() 显示数据的概要。 1234567891011In [19]: df.describe()Out[19]: A B C Dcount 6.000000 6.000000 6.000000 6.000000mean 0.073711 -0.431125 -0.687758 -0.233103std 0.843157 0.922818 0.779887 0.973118min -0.861849 -2.104569 -1.509059 -1.13563225% -0.611510 -0.600794 -1.368714 -1.07661050% 0.022070 -0.228039 -0.767252 -0.38618875% 0.658444 0.041933 -0.034326 0.461706max 1.212112 0.567020 0.276232 1.071804 和 numpy 一样，可以方便的得到转置 1234567In [20]: df.TOut[20]: 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06A 0.469112 1.212112 -0.861849 0.721555 -0.424972 -0.673690B -0.282863 -0.173215 -2.104569 -0.706771 0.567020 0.113648C -1.509059 0.119209 -0.494929 -1.039575 0.276232 -1.478427D -1.135632 -1.044236 1.071804 0.271860 -1.087401 0.524988 对 axis 按照 index 排序（axis=1 是指第二个维度，即：列，axis=0 是指第一个维度，即：行） 123456789In [21]: df.sort_index(axis=1, ascending=False) #ascending=False 默认为True，升序Out[21]: D C B A2013-01-01 -1.135632 -1.509059 -0.282863 0.4691122013-01-02 -1.044236 0.119209 -0.173215 1.2121122013-01-03 1.071804 -0.494929 -2.104569 -0.8618492013-01-04 0.271860 -1.039575 -0.706771 0.7215552013-01-05 -1.087401 0.276232 0.567020 -0.4249722013-01-06 0.524988 -1.478427 0.113648 -0.673690 按值排序 123456789In [22]: df.sort_values(by='B') #也可以是by=['A','B']，按2列排序Out[22]: A B C D2013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.2718602013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-06 -0.673690 0.113648 -1.478427 0.5249882013-01-05 -0.424972 0.567020 0.276232 -1.087401 选择 注意，以下这些对交互式环境很友好，但是作为 production code 请用优化过的 .at, .iat, .loc, .iloc 和 .ix 获取行/列从 DataFrame 选择一个列，就得到了 Series 123456789In [23]: df['A']Out[23]: 2013-01-01 0.4691122013-01-02 1.2121122013-01-03 -0.8618492013-01-04 0.7215552013-01-05 -0.4249722013-01-06 -0.673690Freq: D, Name: A, dtype: float64 和 numpy 类似，这里也能用 []选择行 12345678910111213In [24]: df[0:3]Out[24]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.071804In [25]: df['20130102':'20130104']Out[25]: A B C D2013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-03 -0.861849 -2.104569 -0.494929 1.0718042013-01-04 0.721555 -0.706771 -1.039575 0.271860 通过 label 选择还可以多选 123456789In [27]: df.loc[:,['A','B']] #所有行，AB列Out[27]: A B2013-01-01 0.469112 -0.2828632013-01-02 1.212112 -0.1732152013-01-03 -0.861849 -2.1045692013-01-04 0.721555 -0.7067712013-01-05 -0.424972 0.5670202013-01-06 -0.673690 0.113648 注意那个冒号，用法和 MATLAB 或 NumPy 是一样的！所以也可以这样 123456In [28]: df.loc['20130102':'20130104',['A','B']] Out[28]: A B2013-01-02 1.212112 -0.1732152013-01-03 -0.861849 -2.1045692013-01-04 0.721555 -0.706771 12345In [29]: df.loc['20130102',['A','B']]Out[29]: A 1.212112B -0.173215Name: 2013-01-02 00:00:00, dtype: float64 如果对所有的维度都写了标量，不就是选出一个元素吗？ 如果对所有的维度都写了标量，不就是选出一个元素吗？ 12In [30]: df.loc[dates[0],'A']Out[30]: 0.46911229990718628 这种情况通常用 at ，速度更快 12In [31]: df.at[dates[0],'A']Out[31]: 0.46911229990718628 通过整数下标选择这个就和数组类似啦，直接看例子。选出第3行： 1234567In [32]: df.iloc[3]Out[32]: A 0.721555B -0.706771C -1.039575D 0.271860Name: 2013-01-04 00:00:00, dtype: float64 选出3~4行，0~1列： 12345In [33]: df.iloc[3:5,0:2] #注意 3:5 是第3行到第4行（有第0行）Out[33]: A B2013-01-04 0.721555 -0.7067712013-01-05 -0.424972 0.567020 也能用 list 选择 123456In [34]: df.iloc[[1,2,4],[0,2]]Out[34]: A C2013-01-02 1.212112 0.1192092013-01-03 -0.861849 -0.4949292013-01-05 -0.424972 0.276232 对应单个元素 1234In [37]: df.iloc[1,1]Out[37]: -0.17321464905330858In [38]: df.iat[1,1]Out[38]: -0.17321464905330858 总结：df.icol 是按下标选择，df.col是按标签选择。 通过布尔值下标基本用法 123456In [39]: df[df.A &gt; 0]Out[39]: A B C D2013-01-01 0.469112 -0.282863 -1.509059 -1.1356322013-01-02 1.212112 -0.173215 0.119209 -1.0442362013-01-04 0.721555 -0.706771 -1.039575 0.271860 不满足条件的填充为： NaN 123456789In [40]: df[df &gt; 0]Out[40]: A B C D2013-01-01 0.469112 NaN NaN NaN2013-01-02 1.212112 NaN 0.119209 NaN2013-01-03 NaN NaN NaN 1.0718042013-01-04 0.721555 NaN NaN 0.2718602013-01-05 NaN 0.567020 0.276232 NaN2013-01-06 NaN 0.113648 NaN 0.524988 isin() 函数：是否在集合中 12345678910111213141516171819In [41]: df2 = df.copy()In [42]: df2['E'] = ['one', 'one','two','three','four','three']In [43]: df2Out[43]: A B C D E2013-01-01 0.469112 -0.282863 -1.509059 -1.135632 one2013-01-02 1.212112 -0.173215 0.119209 -1.044236 one2013-01-03 -0.861849 -2.104569 -0.494929 1.071804 two2013-01-04 0.721555 -0.706771 -1.039575 0.271860 three2013-01-05 -0.424972 0.567020 0.276232 -1.087401 four2013-01-06 -0.673690 0.113648 -1.478427 0.524988 threeIn [44]: df2[df2['E'].isin(['two','four'])]Out[44]: A B C D E2013-01-03 -0.861849 -2.104569 -0.494929 1.071804 two2013-01-05 -0.424972 0.567020 0.276232 -1.087401 four 删除数据丢弃某条轴上的一个或多个项很简单，只要有一个索引数组或列表即可。由于需要执行一些数据整理和集合逻辑，所以drop方法返回的是一个在指定轴上删除了指定值的新对象： 1234567891011In [110]: data = pd.DataFrame(np.arange(16).reshape((4, 4)), .....: index=['Ohio', 'Colorado', 'Utah', 'New York'], .....: columns=['one', 'two', 'three', 'four'])In [111]: dataOut[111]: one two three fourOhio 0 1 2 3Colorado 4 5 6 7Utah 8 9 10 11New York 12 13 14 15 用标签序列调用drop会从行标签（axis 0）删除值： 12345In [112]: data.drop(['Colorado', 'Ohio'])Out[112]: one two three fourUtah 8 9 10 11New York 12 13 14 15 通过传递axis=1或axis=’columns’可以删除列的值： 1234567In [113]: data.drop('two', axis=1)Out[113]: one three fourOhio 0 2 3Colorado 4 6 7Utah 8 10 11New York 12 14 15 读取、写入数据CSV写入 1In [136]: df.to_csv('foo.csv') 读取 12345678In [137]: pd.read_csv('foo.csv')In [137]: pd.read_csv(StringIO(data), names=['foo', 'bar', 'baz'], header=None)# 自定义表头，当name设定的时候，header必须显式None，因为默认为0 foo bar baz0 a b c1 1 2 32 4 5 63 7 8 9 table读取 12data = pd.read_table('example.txt',sep='\t',header=0) # 指定分隔符和表头，默认header=0，把第一行作为表头。分割符默认制表符'/t'，'/s+'，可以匹配任何空格。 excel写入 1In [140]: df.to_excel('foo.xlsx', sheet_name='Sheet1') 读取 12In [141]: pd.read_excel('foo.xlsx', sheet_name='Sheet1', index_col=None, na_values=['NA'])#index_col 行名，na_values 缺失值的形式]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[next主题设置]]></title>
    <url>%2F2018%2F09%2F01%2Fnext-theme%2F</url>
    <content type="text"><![CDATA[主题风格通过修改next主题下的_config.yml的scheme字段，配置不同的风格。 12345# Schemes#scheme: Musescheme: Mist #推荐#scheme: Pisces#scheme: Gemini 菜单通过修改next主题下的_config.yml的menu字段，选定显示的菜单项。 可自己修改字段和目录名，||之后为配套的小图标。我添加了links字段，但是当前语言是简体中文，页面上无法给我翻译出来，去添加language/zh-CN.yml里的对应字段即可。 1234567menu: home: /home/ || home about: /about/ || user #tags: /tags/ || tags categories: /categories/ || th archives: /archives/ || archive links: /links/ || calendar 头像在主题下的source/images/下替换原有的头像文件avatar.gif，并在_config.yml中查找Sidebar Avatar字段，添加url字段内容： /images/avatar.gif 头像旋转找到位于 source/css/_common/components/sidebar/sidebar-author.syl 模板文件里侧边栏头像的样式 .site-author-image 将内容修改为 123456.site-author-image &#123; border-radius: 50%; -webkit-border-radius: 50%; -moz-border-radius: 50%; transition: 1.4s all;&#125; 然后添加 .site-author-image:hover 样式，由 rotate() 方法实现，旋转 360° 123456.site-author-image:hover &#123; -webkit-transform: rotate(360deg); -moz-transform: rotate(360deg); -ms-transform: rotate(360deg); -transform: rotate(360deg);&#125; 文章代码主题Next主题总共支持5种主题，默认主题是白色的normal。通过修改next主题下的_config.yml的highlight字段，来设置代码主题。 推荐 night 。 标签、分类在存在标签页、分类页的情况下，在写文章的时候，在文章头部添加 tags、categories 字段。 12tags: [npm, hexo, github]categories: 搭建博客 搜索功能安装 hexo-generator-searchdb 1$ npm install hexo-generator-searchdb --save 在站点myBlog/_config.yml中添加search字段，如下 12345search:path: search.xmlfield: postformat: htmllimit: 10000 修改next主题下的_config.yml的Local search字段 1enable: true hexo博客底部页脚找到/themes/next/layout/_partials/footer.swig文件 内容如下 1234567891011121314151617181920&lt;div class="copyright" &gt; &#123;% set current = date(Date.now(), "YYYY") %&#125; © &#123;% if theme.since and theme.since != current %&#125; &#123;&#123; theme.since &#125;&#125; - &#123;% endif %&#125; &lt;span itemprop="copyrightYear"&gt;&#123;&#123; current &#125;&#125;&lt;/span&gt; &lt;span class="with-love"&gt; &lt;i class="fa fa-heart"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class="author" itemprop="copyrightHolder"&gt;&#123;&#123; config.author &#125;&#125;&lt;/span&gt;&lt;/div&gt;&lt;div class="powered-by"&gt; &#123;&#123; __('footer.powered', '&lt;a class="theme-link" href="https://hexo.io"&gt;Hexo&lt;/a&gt;') &#125;&#125;&lt;/div&gt;&lt;div class="theme-info"&gt; &#123;&#123; __('footer.theme') &#125;&#125; - &lt;a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"&gt; NexT.&#123;&#123; theme.scheme &#125;&#125; &lt;/a&gt;&lt;/div&gt; 删除class 为powered-by的div和theme-info的div。 github标识在网站上选择一个喜欢的标识类型，复制粘贴代码到themes/next/layout/_layout.swig文件中(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;的下面)，并把href改为个人github地址 。 首页隐藏指定文章有时候我们可能只想在首页显示关于编程之类的内容，而个人日记之类的文章放在其他分类之下而不在首页显示。可以从、分类、标签、归档中查看文章。 自定义front-matter的参数例如，自定义添加一个notshow参数，值为true，用来提供判断 123tags: [npm, hexo, github]categories: 搭建博客notshow: true 修改主题的themes/next/layout/index.swig文件,将 123456789&#123;% block content %&#125; &lt;section id="posts" class="posts-expand"&gt; &#123;% for post in page.posts %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endfor %&#125; &lt;/section&gt; &#123;% include '_partials/pagination.swig' %&#125;&#123;% endblock % 添加过滤条件 1234567891011&#123;% block content %&#125; &lt;section id="posts" class="posts-expand"&gt; &#123;% for post in page.posts %&#125; &#123;% if post.notshow != true %&#125; &#123;&#123; post_template.render(post, true) &#125;&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;/section&gt; &#123;% include '_partials/pagination.swig' %&#125;&#123;% endblock %&#125;]]></content>
      <categories>
        <category>blog</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[python-copy]]></title>
    <url>%2F2018%2F08%2F27%2Fpython-copy%2F</url>
    <content type="text"><![CDATA[赋值（assignment）在Python中，用一个变量给另一个变量赋值，其实就是给当前内存中的对象增加一个“标签”而已。 12345&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; print(id(a), id(b), sep='\n') #a和b都只是[1,2,3]的一个标签139701469405552139701469405552 浅拷贝（shallow copy）注意：浅拷贝和深拷贝的不同仅仅是对组合对象来说，所谓的组合对象就是包含了其它对象的对象，如列表，类实例。而对于数字、字符串以及其它“原子”类型，没有拷贝一说，产生的都是原对象的引用。 所谓“浅拷贝”，是指创建一个新的对象，其内容是原对象中元素的引用。（拷贝组合对象，不拷贝子对象） 常见的浅拷贝有：切片操作、工厂函数（如list()，dict()等）、对象的copy()方法、copy模块中的copy函数。 12345678910&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = list(a)&gt;&gt;&gt; print(id(a), id(b)) # a和b身份不同140601785066200 140601784764968&gt;&gt;&gt; for x, y in zip(a, b): # 但它们包含的子对象身份相同... print(id(x), id(y))... 140601911441984 140601911441984140601911442016 140601911442016140601911442048 140601911442048 从上面可以明显的看出来，a 浅拷贝得到 b，a 和 b 指向内存中不同的 list 对象，但它们的元素却指向相同的 int 对象。这就是浅拷贝！ 1234567&gt;&gt;&gt; a = [1, 2, 3，[4,5]]&gt;&gt;&gt; b = list(a)&gt;&gt;&gt; a[-1].append(6)&gt;&gt;&gt; print(a)[1, 2, 3，[4,5,6]]&gt;&gt;&gt; print(b) #当a的子对象发生改变时，b也发生了改变[1, 2, 3，[4,5,6]] 深拷贝（deep copy）所谓“深拷贝”，是指创建一个新的对象，然后递归的拷贝原对象所包含的子对象。深拷贝出来的对象与原对象没有任何关联。 深拷贝只有一种方式：copy模块中的deepcopy函数。 12345678&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3，[4,5]]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; a[-1].append(6)&gt;&gt;&gt; print(a)[1, 2, 3，[4,5,6]]&gt;&gt;&gt; print(b) #当a的子对象发生改变时，b不发生改变[1, 2, 3，[4,5]] 1234567891011&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; print(id(a), id(b))140601785065840 140601785066200&gt;&gt;&gt; for x, y in zip(a, b):... print(id(x), id(y))... 140601911441984 140601911441984140601911442016 140601911442016140601911442048 140601911442048 看了上面的例子，有人可能会疑惑： 为什么使用了深拷贝，a和b中元素的id还是一样呢？ 答：这是因为对于不可变对象，当需要一个新的对象时，python可能会返回已经存在的某个类型和值都一致的对象的引用。而且这种机制并不会影响 a 和 b 的相互独立性，因为当两个元素指向同一个不可变对象时，对其中一个赋值不会影响另外一个。 我们可以用一个包含可变对象的列表来确切地展示“浅拷贝”与“深拷贝”的区别： 1234567891011121314151617181920&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [[1, 2],[5, 6], [8, 9]]&gt;&gt;&gt; b = copy.copy(a) # 浅拷贝得到b&gt;&gt;&gt; c = copy.deepcopy(a) # 深拷贝得到c&gt;&gt;&gt; print(id(a), id(b)) # a 和 b 不同139832578518984 139832578335520&gt;&gt;&gt; for x, y in zip(a, b): # a 和 b 的子对象相同... print(id(x), id(y))... 139832578622816 139832578622816139832578622672 139832578622672139832578623104 139832578623104&gt;&gt;&gt; print(id(a), id(c)) # a 和 c 不同139832578518984 139832578622456&gt;&gt;&gt; for x, y in zip(a, c): # a 和 c 的子对象也不同... print(id(x), id(y))... 139832578622816 139832578621520139832578622672 139832578518912139832578623104 139832578623392 总结：1、赋值：简单地拷贝对象的引用，两个对象的id相同。2、浅拷贝：创建一个新的组合对象，这个新对象与原对象共享内存中的子对象。3、深拷贝：创建一个新的组合对象，同时递归地拷贝所有子对象，新的组合对象与原对象没有任何关联。虽然实际上会共享不可变的子对象，但不影响它们的相互独立性。 浅拷贝和深拷贝的不同仅仅是对组合对象来说，所谓的组合对象就是包含了其它对象的对象，如列表，类实例。而对于数字、字符串(如a=1)以及其它“原子”类型，没有拷贝一说，产生的都是原对象的引用。]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ruby-re]]></title>
    <url>%2F2018%2F08%2F21%2Fruby-re%2F</url>
    <content type="text"><![CDATA[Ruby中正则表达式的写法主要有三种 在//之间，要进行转义 在%r{}内，不用进行转义 Regexp.new()内，不用进行转义 匹配的两种方法 =~肯定匹配, !~否定匹配。=~表达式返回匹配到的位置索引，失败返回nil，符号左右内容可交换 regexp#match(str)，返回MatchData，一个数组，从0开始，还有match.pre_match返回匹配前内容，match.post_match返回匹配后内容 1234/cat/ =~ "dog and cat" #返回8# 类似python可以将正则放入一个变量，如re = Regexp.new(/cat/)，在后续匹配时直接使用remt = /cat/.match("bigcatcomes") # mt = re.match("bigcatcomes")"#&#123;mt.pre_match&#125;-&gt;#&#123;mt[0]&#125;&lt;-#&#123;mt.post_match&#125;" #返回big-&gt;cat&lt;-comes 替换很多时候匹配是为了替换，Ruby中进行正则替换非常简单，两个方法即可搞定，sub()+gsub()。sub只替换第一次匹配，gsub（g:global）会替换所有的匹配，没有匹配到返回原字符串的copy 123str = "ABDADA"new_str = str.sub(/A/, "a") #返回"aBDADA"new_str2 = str.gsub(/A/, "a") #返回"aBDaDa" 分组匹配Ruby的分组匹配与其它语言差别不大，分组匹配表达式是对要进行分组的内容加()。对于匹配到的结果，可以用系统变量$1，$2…索引，也可用matchData数组来索引 123md = /(\d\d):(\d\d)(..)/.match("12:50am") # md为一个MatchData对象puts "Hour is #&#123;$1&#125;, minute #&#123;$2&#125;"puts "Hour is #&#123;md[1]&#125;, minute #&#123;md[2]&#125;" 匹配所有regexp#match()只能匹配一次，如果想匹配所有要用regexp#scan()用法示例： 1"abcabcqwe".scan(%r&#123;abc&#125;).each &#123;|x| puts x&#125; # 输出2行abc]]></content>
      <categories>
        <category>ruby</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[hexo+github搭建博客]]></title>
    <url>%2F2018%2F08%2F09%2Fhexo%2Bgithub%2F</url>
    <content type="text"><![CDATA[准备node.js和git node.js : 直接官网下载 git : 直接官网下载 验证安装结果 : 1234$ node -v$ npm -v#npm是随同NodeJS一起安装的包管理工具,类似python的pip$ git --version Github账户注册和新建项目项目必须要遵守格式：uername.github.io，如下： 安装Hexo Hexo 是一个快速、简洁且高效的博客框架。 12345$ mkdir blog &amp;&amp; cd - #创建个人目录$ npm install -g hexo-cli #安装hexo$ hexo -v #检查hexo$ hexo init #初始化hexo$ npm install #安装所需包 Hexo与Github page关联 设置Git的user name和email（如果是第一次的话） 12git config --global user.name "xxx" git用户名git config --global user.email "xxx@xx.com" git邮箱 生成密钥、公钥 1234$ ssh-add -D$ rm -r ~/.ssh #删除存在的密钥、公钥$ ssh-keygen -t rsa -C "xxx@xx.com" #生成新密钥、公钥对应git邮箱$ cat ~/.ssh/id_rsa.pub #查看公钥内容 添加公钥到github 登陆github帐户，点击头像，然后 Settings -&gt; 左栏点击 SSH and GPG keys -&gt; 点击 New SSH key。然后复制上面的公钥内容，粘贴进“Key”文本域内。 title随便起个名字，点击 Add key完成。 确认成功 1234$ ssh -T xxx@github.com$ git remote -vorigin https://github.com/someaccount/someproject.git (fetch)origin https://github.com/someaccount/someproject.git (push) git使用https协议，每次pull, push都会提示要输入密码，使用git协议，然后使用ssh密钥，这样免去每次都输密码的麻烦。 SSH地址 HTTPS地址 在_config.yml 进行基础配置回到创建hexo的文件夹找到_config.yml，并编辑最后的信息: 12345deploy： type： git repository ：git@github.com:flystar233/flystar233.github.io.git #发布不再需要密码 repository ：https://github.com/flystar233/flystar233.github.io.git #发布需要密码 branch ：master 让博客能加载图片12post_asset_folder: true #在_config.yml中将false改为true$ npm install hexo-asset-image --save #在命令行中执行 这样之后，在运行hexo n &quot;xxxx&quot;来生成md博客时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹。将博客所需图片放入此文件夹中，在md文件中（博客内容）插入图片时，使用命令![](xxxx/pic.png)#md插入图片公式 来插入图片，xxxx是文件夹的名字，路径不可有中文。 发布博客在生成以及部署文章之前，需要安装一个扩展： 1$ npm install hexo-deployer-git --save 发布相关命令 123456$ hexo clean # 清除全部文章$ hexo generate == hexo g #生成静态文件$ hexo deploy == hexo d #部署文件到github$ hexo new "文件名" #创建新文章$ hexo new page "页面名" #创建新页面$ hexo server #开启预览访问端口（默认端口4000，'ctrl + c'关闭server） 查看博客 部署成功后访问博客地址，如：flystar233.github.io]]></content>
      <categories>
        <category>blog</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[awk]]></title>
    <url>%2F2018%2F08%2F08%2Fawk%2F</url>
    <content type="text"><![CDATA[使用awk 取文件第一列是以数字开头的数据： 1$ awk '$1~/^[0-9]+/ &#123;print $0&#125;' infile &gt; outfile 使用awk 取文件第一列包含chr或者包含sca： 1$ awk '$1~/chr|sca/ &#123;print $0&#125;' infile &gt; outfile 使用awk 取文件第一列大于0.1且小于0.5的数据： 1$ awk '$1&gt;0.1 &amp;&amp; $1&lt;0.5 &#123;print $0&#125;' infile &gt; outfile 使用awk 取文件第一列是chr： 12$ awk '$1~/^chr$/ &#123;print $0&#125;' infile &gt; outfile$ awk '$1=="chr" &#123;print $0&#125;' infile &gt; outfile 使用awk 进行字符串捕获： 1234$ cat fileaaaaBASE_DDDD123$ awk '&#123;match($0,/(BASE_[a-zA-Z0-9]+)/,a);print a[1]&#125;' fileBASE_DDDD123 使用awk 进行格式化输出： 12# %c 字符 %s 字符串 %d 十进制整数 %f 浮点数$ printf ("%s\t%s\t%s",$1,$2,$3)]]></content>
      <categories>
        <category>awk</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[world]]></title>
    <url>%2F2018%2F08%2F07%2Fworld%2F</url>
    <content type="text"><![CDATA[要了解世界的概念就要不断的减少个体的差异性。 我们知道人生而不同，但是要在脑海中形成对世界的认识，就要减少对相同类不同个体的存在，然后逐渐逼近对世界的正确认识。 世界是人在运行的么？不是。人只是世界很小的一个产物，人的主观能动性使人类科技，社会发展，那么人已经拥有可以控制世界的能力了么？小点说，人类已经拥有可以控制地球的能力了么？没有。人类在不断的进步中，还是在顺应自然的变化。 世界是太阳运行的么？不是。太阳为地球所有的生物提供了生存的条件：能量，万物生长，在地球上形成自然环境。那么，太阳会消失么？会的，太阳不断地核聚变产生能量，也在不断的泯灭，终有一天，太阳不在发出光芒，如果人类没有最终造出太阳的替代品，那么地球也将会消失。那么世界不再运行了么？没有。太阳系在已知宇宙中小的就像沧海一粟，一块皮肤老了，掉了也无所谓。 世界是光运行的么？只能说，光是一个必要不充分条件。没有光，世界万物无法生长，世界没有生机，没有了活力，没有了发展的动力。然而，没有光世界还在运行，宇宙深处没有光线，只有天体，他们依然按照旋转规律不停地运动，如果你觉得没有光，怎么知道有天体在动，那你可以做个小小的实验：找一个不透光的长盒子，两端开口，把一个小球扔进去，那么一定会在另一端小球出来。你看见小球在里边的运动了么？没有。你知道小球在动么？知道。 世界根本没有事物在操纵运行，完全是按照无序的规律自我运行的么？不知道，最起码现在不知道。我们不能把一切无法了解的事物归于神。神是什么？在外人解释来说，神就是唯心主义，是精神。谁也没见过神，是神造人？还是人造神？…]]></content>
      <categories>
        <category>thought</category>
      </categories>
  </entry>
</search>
